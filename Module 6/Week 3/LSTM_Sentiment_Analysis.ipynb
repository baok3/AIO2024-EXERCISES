{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPe8mExpzvyBr3kS9vriRdi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install unidecode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nO2bKMT-Bjms","executionInfo":{"status":"ok","timestamp":1735000660703,"user_tz":-420,"elapsed":6200,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}},"outputId":"0790b426-b7f0-44d4-aa2d-e43bdc6fc9bc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unidecode\n","  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n","Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.3.8\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"jzCIcRZCt72T","executionInfo":{"status":"ok","timestamp":1735000675985,"user_tz":-420,"elapsed":15285,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b16d34f5-9405-4677-84f1-4981e35fe870"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","seed = 1\n","torch.manual_seed(seed)\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import nltk\n","import unidecode\n","\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","while not os.path.exists('/content/drive/MyDrive/datasets/dataset'):\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/datasets/dataset\n","\n"],"metadata":{"id":"81vd6LdF33D2","executionInfo":{"status":"ok","timestamp":1735000737843,"user_tz":-420,"elapsed":61868,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0bd3c2c5-21a0-4788-946a-db4889ab2293"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/datasets/dataset\n"]}]},{"cell_type":"code","source":["dataset_path = 'all-data.csv'\n","headers = ['sentiment', 'content']\n","df = pd.read_csv(\n","    dataset_path,\n","    names=headers,\n","    encoding='ISO-8859-1'\n",")"],"metadata":{"id":"wwkcsQJ-5IN0","executionInfo":{"status":"ok","timestamp":1735000739127,"user_tz":-420,"elapsed":1288,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["classes = {\n","    class_name : idx for idx, class_name in enumerate(df['sentiment'].unique().tolist())\n","}\n","df['sentiment'] = df['sentiment'].apply(lambda x: classes[x])"],"metadata":{"id":"g3-VWFo05cLI","executionInfo":{"status":"ok","timestamp":1735000739127,"user_tz":-420,"elapsed":4,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["english_stop_words = stopwords.words('english')\n","stemmer = PorterStemmer()\n","\n","def text_normalize(text):\n","  text = text.lower()\n","  text = unidecode.unidecode(text)\n","  text = text.strip()\n","  text = re.sub(r'[^\\w\\s]', '', text)\n","  text = ' '.join([word for word in text.split(' ') if word not in english_stop_words])\n","  text = ' '.join([stemmer.stem(word) for word in text.split(' ')])\n","  return text\n","\n","df['content'] = df['content'].apply(lambda x: text_normalize(x))"],"metadata":{"id":"chOYbofPBK5b","executionInfo":{"status":"ok","timestamp":1735000744264,"user_tz":-420,"elapsed":5140,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["vocab = []\n","for sentence in df['content'].tolist():\n","    tokens = sentence.split()\n","    for token in tokens:\n","        vocab.append(token)\n","vocab.append('UNK')\n","vocab.append('PAD')\n","word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n","vocal_size = len(vocab)"],"metadata":{"id":"hYmsQ-zcJGQ7","executionInfo":{"status":"ok","timestamp":1735000744264,"user_tz":-420,"elapsed":7,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def transform(text, word_to_idx, max_seq_len):\n","  tokens = []\n","  for w in text.split():\n","    try:\n","      w_ids = word_to_idx[w]\n","    except:\n","      w_ids = word_to_idx['UNK']\n","    tokens.append(w_ids)\n","\n","  if len(tokens) < max_seq_len:\n","    tokens += [word_to_idx['PAD']] * (max_seq_len - len(tokens))\n","\n","  elif len(tokens) > max_seq_len:\n","    tokens = tokens[:max_seq_len]\n","\n","  return tokens"],"metadata":{"id":"XdgnAQiuJ4QZ","executionInfo":{"status":"ok","timestamp":1735000744264,"user_tz":-420,"elapsed":6,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["val_size = 0.2\n","test_size = 0.125\n","is_shuffle = True\n","texts = df['content'].tolist()\n","labels = df['sentiment'].tolist()\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    texts,\n","    labels,\n","    test_size=val_size,\n","    random_state=seed,\n","    shuffle=is_shuffle\n",")\n","\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_val,\n","    y_val,\n","    test_size=val_size,\n","    random_state=seed,\n","    shuffle=is_shuffle\n",")"],"metadata":{"id":"C9gDMgFBBEY8","executionInfo":{"status":"ok","timestamp":1735000744264,"user_tz":-420,"elapsed":6,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class FinacialNews(Dataset):\n","  def __init__(self, X, y, word_to_idx, max_seq_len, transform=None):\n","    self.texts = X\n","    self.labels = y\n","    self.word_to_idx = word_to_idx\n","    self.max_seq_len = max_seq_len\n","    self.transform = transform\n","\n","  def __len__(self):\n","    return len(self.texts)\n","\n","  def __getitem__(self, idx):\n","    text = self.texts[idx]\n","    label = self.labels[idx]\n","\n","    if self.transform:\n","      text = self.transform(\n","          text,\n","          self.word_to_idx,\n","          self.max_seq_len\n","          )\n","    text = torch.tensor(text)\n","\n","    return text, label"],"metadata":{"id":"mZ54l1xoBdK2","executionInfo":{"status":"ok","timestamp":1735000744264,"user_tz":-420,"elapsed":5,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["max_seq_len = 32\n","\n","train_dataset = FinacialNews(\n","    X_train, y_train,\n","    word_to_idx = word_to_idx,\n","    max_seq_len = max_seq_len,\n","    transform=transform\n",")\n","\n","val_dataset = FinacialNews(\n","    X_val,\n","    y_val,\n","    word_to_idx = word_to_idx,\n","    max_seq_len = max_seq_len,\n","    transform=transform\n",")\n","\n","test_dataset = FinacialNews(\n","    X_test,\n","    y_test,\n","    word_to_idx = word_to_idx,\n","    max_seq_len = max_seq_len,\n","    transform=transform\n",")\n","\n","train_batch_size = 128\n","test_batch_size = 8\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=train_batch_size,\n","    shuffle=True\n",")\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")"],"metadata":{"id":"yO429fDbCf8T","executionInfo":{"status":"ok","timestamp":1735000744264,"user_tz":-420,"elapsed":5,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class SentimentClassifier(nn.Module):\n","  def __init__(\n","      self,\n","      vocab_size, embedding_dim, hidden_size, n_layers, n_classes, dropout_prob\n","  ):\n","    super(SentimentClassifier, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    self.lstm = nn.LSTM(embedding_dim, hidden_size, n_layers, batch_first = True)\n","    self.norm = nn.LayerNorm(hidden_size)\n","    self.dropout = nn.Dropout(dropout_prob)\n","    self.fc1 = nn.Linear(hidden_size, 16)\n","    self.relu = nn.ReLU()\n","    self.fc2 = nn.Linear(16, n_classes)\n","\n","  def forward(self, x):\n","    x = self.embedding(x)\n","    x, hn = self.lstm(x)\n","    x = x[:, -1, :]\n","    x = self.norm(x)\n","    x = self.dropout(x)\n","    x = self.fc1(x)\n","    x = self.relu(x)\n","    x = self.fc2(x)\n","    return x\n"],"metadata":{"id":"7oo67h7nC2EQ","executionInfo":{"status":"ok","timestamp":1735000744265,"user_tz":-420,"elapsed":5,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["n_classes = len(list(classes.keys()))\n","embedding_dim = 64\n","hidden_size = 64\n","n_layers = 2\n","dropout_prob = 0.2\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model = SentimentClassifier(\n","    vocal_size,\n","    embedding_dim,\n","    hidden_size,\n","    n_layers,\n","    n_classes,\n","    dropout_prob\n",").to(device)"],"metadata":{"id":"kJ9F3wourKXj","executionInfo":{"status":"ok","timestamp":1735000744265,"user_tz":-420,"elapsed":5,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["lr = 1e-4\n","epochs = 50\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"],"metadata":{"id":"qE3MDDngrp-Y","executionInfo":{"status":"ok","timestamp":1735000749926,"user_tz":-420,"elapsed":5666,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def fit(model, train_loader, val_loader, criterion, optimizer, device, epochs):\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(epochs):\n","        batch_train_losses = []\n","\n","        model.train()\n","        for idx, (inputs, labels) in enumerate(train_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            batch_train_losses.append(loss.item())\n","\n","        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n","        train_losses.append(train_loss)\n","\n","        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n","        val_losses.append(val_loss)\n","\n","        print(f'Epoch {epoch + 1}/{epochs}, train loss: {train_loss}, val loss: {val_loss}')\n","    return train_losses, val_losses\n","\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    losses = []\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            losses.append(loss.item())\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    loss = sum(losses) / len(losses)\n","    acc = correct / total\n","\n","    return loss, acc"],"metadata":{"id":"0422RfTQrxrS","executionInfo":{"status":"ok","timestamp":1735000749927,"user_tz":-420,"elapsed":4,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["train_losses, val_losses = fit(model, train_loader, val_loader, criterion, optimizer, device, epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBmrutZ3sHY8","executionInfo":{"status":"ok","timestamp":1735001015197,"user_tz":-420,"elapsed":265273,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}},"outputId":"fa14bb04-5b89-4904-a5bc-7e2758ea598c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, train loss: 1.0405128002166748, val loss: 0.9621154020742043\n","Epoch 2/50, train loss: 0.9394433882928663, val loss: 0.9271791356126058\n","Epoch 3/50, train loss: 0.9330969260584924, val loss: 0.9243879474929928\n","Epoch 4/50, train loss: 0.9269166319600998, val loss: 0.9239668047305235\n","Epoch 5/50, train loss: 0.9287008854650682, val loss: 0.9235882630053255\n","Epoch 6/50, train loss: 0.926802392928831, val loss: 0.9232526710352946\n","Epoch 7/50, train loss: 0.9248798931798627, val loss: 0.9232955630292597\n","Epoch 8/50, train loss: 0.9321534614409169, val loss: 0.9228211450822574\n","Epoch 9/50, train loss: 0.923467799540489, val loss: 0.9231092478196645\n","Epoch 10/50, train loss: 0.927319388235769, val loss: 0.9220227310337972\n","Epoch 11/50, train loss: 0.9264813853848365, val loss: 0.9219882457526689\n","Epoch 12/50, train loss: 0.9218909009810416, val loss: 0.9213922607530024\n","Epoch 13/50, train loss: 0.924066307083253, val loss: 0.9208797136532891\n","Epoch 14/50, train loss: 0.9248997357583815, val loss: 0.9237293834538803\n","Epoch 15/50, train loss: 0.9280165107019486, val loss: 0.9194059132300701\n","Epoch 16/50, train loss: 0.9174763329567448, val loss: 0.9177511008744387\n","Epoch 17/50, train loss: 0.9177063607400463, val loss: 0.913037135428989\n","Epoch 18/50, train loss: 0.9096933141831429, val loss: 0.9051814171456799\n","Epoch 19/50, train loss: 0.9030056192028907, val loss: 0.9048550503770101\n","Epoch 20/50, train loss: 0.8906705840941398, val loss: 0.8956419696512911\n","Epoch 21/50, train loss: 0.876331498545985, val loss: 0.9002330207947603\n","Epoch 22/50, train loss: 0.8747248418869511, val loss: 0.8891859521570894\n","Epoch 23/50, train loss: 0.8607396752603592, val loss: 0.8811813301032352\n","Epoch 24/50, train loss: 0.8525559863736553, val loss: 0.8783817374214684\n","Epoch 25/50, train loss: 0.8448378097626471, val loss: 0.8747042574218868\n","Epoch 26/50, train loss: 0.8352446209999823, val loss: 0.8887464947921714\n","Epoch 27/50, train loss: 0.824574064823889, val loss: 0.8745737807037904\n","Epoch 28/50, train loss: 0.817506976665989, val loss: 0.873814821857767\n","Epoch 29/50, train loss: 0.8105864390250175, val loss: 0.8853582199086848\n","Epoch 30/50, train loss: 0.809794302909605, val loss: 0.8721398594453162\n","Epoch 31/50, train loss: 0.8068400794459928, val loss: 0.8858966412617988\n","Epoch 32/50, train loss: 0.7974534534638927, val loss: 0.8767968345548689\n","Epoch 33/50, train loss: 0.7950689350405047, val loss: 0.8755048356719852\n","Epoch 34/50, train loss: 0.7830500871904434, val loss: 0.8800680102761259\n","Epoch 35/50, train loss: 0.7779367585336009, val loss: 0.8961228608470602\n","Epoch 36/50, train loss: 0.7688759546126088, val loss: 0.9082991526913398\n","Epoch 37/50, train loss: 0.7618842663303498, val loss: 0.8871111095566111\n","Epoch 38/50, train loss: 0.7514540764593309, val loss: 0.8881497017501556\n","Epoch 39/50, train loss: 0.7495509597562975, val loss: 0.8896145974237895\n","Epoch 40/50, train loss: 0.7450416799514524, val loss: 0.9059214146481347\n","Epoch 41/50, train loss: 0.7295003437226818, val loss: 0.904144679455413\n","Epoch 42/50, train loss: 0.7242562443979325, val loss: 0.9198339320335192\n","Epoch 43/50, train loss: 0.7176716481485674, val loss: 0.9148237994036723\n","Epoch 44/50, train loss: 0.7075226056960321, val loss: 0.9039486926241019\n","Epoch 45/50, train loss: 0.7337264956966523, val loss: 0.901110948053832\n","Epoch 46/50, train loss: 0.6945374954131341, val loss: 0.9302909690694711\n","Epoch 47/50, train loss: 0.6827898217785743, val loss: 0.9404224049799221\n","Epoch 48/50, train loss: 0.6848961441747604, val loss: 0.9562748983963248\n","Epoch 49/50, train loss: 0.6879165691714133, val loss: 0.9419364763289383\n","Epoch 50/50, train loss: 0.672982511981841, val loss: 0.9149396932616676\n"]}]},{"cell_type":"code","source":["val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n","test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n","\n","print(f'Val loss: {val_loss}, Val acc: {val_acc}')\n","print(f'Test loss: {test_loss}, Test acc: {test_acc}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OkVW5_bBw7Zh","executionInfo":{"status":"ok","timestamp":1735001015569,"user_tz":-420,"elapsed":381,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}},"outputId":"696ee12a-f589-4b11-a00d-a516fc69565d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Val loss: 0.9149396932616676, Val acc: 0.6391752577319587\n","Test loss: 0.8444658648967743, Test acc: 0.6391752577319587\n"]}]}]}