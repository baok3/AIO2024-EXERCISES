{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNIAksqCvNy4NPAJV4TIyT6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install unidecode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nO2bKMT-Bjms","executionInfo":{"status":"ok","timestamp":1735003740677,"user_tz":-420,"elapsed":4973,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}},"outputId":"fa491db8-01b9-4c16-a084-66ceee13be47"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\n"]}]},{"cell_type":"code","execution_count":57,"metadata":{"id":"jzCIcRZCt72T","executionInfo":{"status":"ok","timestamp":1735003740677,"user_tz":-420,"elapsed":6,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b9d31e2-aaf5-4886-f969-858dfec809b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","seed = 1\n","torch.manual_seed(seed)\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import re\n","import nltk\n","import unidecode\n","\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","while not os.path.exists('/content/drive/MyDrive/datasets/dataset'):\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/datasets/dataset\n","\n"],"metadata":{"id":"81vd6LdF33D2","executionInfo":{"status":"ok","timestamp":1735003740677,"user_tz":-420,"elapsed":4,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["dataset_path = 'all-data.csv'\n","headers = ['sentiment', 'content']\n","df = pd.read_csv(\n","    dataset_path,\n","    names=headers,\n","    encoding='ISO-8859-1'\n",")"],"metadata":{"id":"wwkcsQJ-5IN0","executionInfo":{"status":"ok","timestamp":1735003740677,"user_tz":-420,"elapsed":4,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["classes = {\n","    class_name : idx for idx, class_name in enumerate(df['sentiment'].unique().tolist())\n","}\n","df['sentiment'] = df['sentiment'].apply(lambda x: classes[x])"],"metadata":{"id":"g3-VWFo05cLI","executionInfo":{"status":"ok","timestamp":1735003740677,"user_tz":-420,"elapsed":3,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["english_stop_words = stopwords.words('english')\n","stemmer = PorterStemmer()\n","\n","def text_normalize(text):\n","  text = text.lower()\n","  text = unidecode.unidecode(text)\n","  text = text.strip()\n","  text = re.sub(r'[^\\w\\s]', '', text)\n","  text = ' '.join([word for word in text.split(' ') if word not in english_stop_words])\n","  text = ' '.join([stemmer.stem(word) for word in text.split(' ')])\n","  return text\n","\n","df['content'] = df['content'].apply(lambda x: text_normalize(x))"],"metadata":{"id":"chOYbofPBK5b","executionInfo":{"status":"ok","timestamp":1735003742883,"user_tz":-420,"elapsed":2209,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["vocab = []\n","for sentence in df['content'].tolist():\n","    tokens = sentence.split()\n","    for token in tokens:\n","        vocab.append(token)\n","vocab.append('UNK')\n","vocab.append('PAD')\n","word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n","vocal_size = len(vocab)"],"metadata":{"id":"hYmsQ-zcJGQ7","executionInfo":{"status":"ok","timestamp":1735003742883,"user_tz":-420,"elapsed":9,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["def transform(text, word_to_idx, max_seq_len):\n","  tokens = []\n","  for w in text.split():\n","    try:\n","      w_ids = word_to_idx[w]\n","    except:\n","      w_ids = word_to_idx['UNK']\n","    tokens.append(w_ids)\n","\n","  if len(tokens) < max_seq_len:\n","    tokens += [word_to_idx['PAD']] * (max_seq_len - len(tokens))\n","\n","  elif len(tokens) > max_seq_len:\n","    tokens = tokens[:max_seq_len]\n","\n","  return tokens"],"metadata":{"id":"XdgnAQiuJ4QZ","executionInfo":{"status":"ok","timestamp":1735003742884,"user_tz":-420,"elapsed":9,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["val_size = 0.2\n","test_size = 0.125\n","is_shuffle = True\n","texts = df['content'].tolist()\n","labels = df['sentiment'].tolist()\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    texts,\n","    labels,\n","    test_size=val_size,\n","    random_state=seed,\n","    shuffle=is_shuffle\n",")\n","\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_val,\n","    y_val,\n","    test_size=val_size,\n","    random_state=seed,\n","    shuffle=is_shuffle\n",")"],"metadata":{"id":"C9gDMgFBBEY8","executionInfo":{"status":"ok","timestamp":1735003742884,"user_tz":-420,"elapsed":8,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["class FinacialNews(Dataset):\n","  def __init__(self, X, y, word_to_idx, max_seq_len, transform=None):\n","    self.texts = X\n","    self.labels = y\n","    self.word_to_idx = word_to_idx\n","    self.max_seq_len = max_seq_len\n","    self.transform = transform\n","\n","  def __len__(self):\n","    return len(self.texts)\n","\n","  def __getitem__(self, idx):\n","    text = self.texts[idx]\n","    label = self.labels[idx]\n","\n","    if self.transform:\n","      text = self.transform(\n","          text,\n","          self.word_to_idx,\n","          self.max_seq_len\n","          )\n","    text = torch.tensor(text)\n","\n","    return text, label"],"metadata":{"id":"mZ54l1xoBdK2","executionInfo":{"status":"ok","timestamp":1735003742884,"user_tz":-420,"elapsed":7,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["max_seq_len = 32\n","\n","train_dataset = FinacialNews(\n","    X_train, y_train,\n","    word_to_idx = word_to_idx,\n","    max_seq_len = max_seq_len,\n","    transform=transform\n",")\n","\n","val_dataset = FinacialNews(\n","    X_val,\n","    y_val,\n","    word_to_idx = word_to_idx,\n","    max_seq_len = max_seq_len,\n","    transform=transform\n",")\n","\n","test_dataset = FinacialNews(\n","    X_test,\n","    y_test,\n","    word_to_idx = word_to_idx,\n","    max_seq_len = max_seq_len,\n","    transform=transform\n",")\n","\n","train_batch_size = 128\n","test_batch_size = 8\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=train_batch_size,\n","    shuffle=True\n",")\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")"],"metadata":{"id":"yO429fDbCf8T","executionInfo":{"status":"ok","timestamp":1735003742884,"user_tz":-420,"elapsed":6,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["class SentimentClassifier(nn.Module):\n","  def __init__(\n","      self,\n","      vocab_size, embedding_dim, hidden_size, n_layers, n_classes, dropout_prob\n","  ):\n","    super(SentimentClassifier, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    self.bilstm = nn.LSTM(embedding_dim, hidden_size, n_layers, batch_first = True, bidirectional = True)\n","    self.norm = nn.LayerNorm(hidden_size*2)\n","    self.dropout = nn.Dropout(dropout_prob)\n","    self.fc1 = nn.Linear(hidden_size*2, 16)\n","    self.relu = nn.ReLU()\n","    self.fc2 = nn.Linear(16, n_classes)\n","\n","  def forward(self, x):\n","    x = self.embedding(x)\n","    x, hn = self.bilstm(x)\n","    x = x[:, -1, :]\n","    x = self.norm(x)\n","    x = self.dropout(x)\n","    x = self.fc1(x)\n","    x = self.relu(x)\n","    x = self.fc2(x)\n","    return x\n"],"metadata":{"id":"7oo67h7nC2EQ","executionInfo":{"status":"ok","timestamp":1735003742884,"user_tz":-420,"elapsed":6,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["n_classes = len(list(classes.keys()))\n","embedding_dim = 64\n","hidden_size = 64\n","n_layers = 2\n","dropout_prob = 0.2\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model = SentimentClassifier(\n","    vocal_size,\n","    embedding_dim,\n","    hidden_size,\n","    n_layers,\n","    n_classes,\n","    dropout_prob\n",").to(device)"],"metadata":{"id":"kJ9F3wourKXj","executionInfo":{"status":"ok","timestamp":1735003742884,"user_tz":-420,"elapsed":5,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["lr = 1e-4\n","epochs = 50\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"],"metadata":{"id":"qE3MDDngrp-Y","executionInfo":{"status":"ok","timestamp":1735003742884,"user_tz":-420,"elapsed":5,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["def fit(model, train_loader, val_loader, criterion, optimizer, device, epochs):\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(epochs):\n","        batch_train_losses = []\n","\n","        model.train()\n","        for idx, (inputs, labels) in enumerate(train_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            batch_train_losses.append(loss.item())\n","\n","        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n","        train_losses.append(train_loss)\n","\n","        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n","        val_losses.append(val_loss)\n","\n","        print(f'Epoch {epoch + 1}/{epochs}, train loss: {train_loss}, val loss: {val_loss}')\n","    return train_losses, val_losses\n","\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    losses = []\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            losses.append(loss.item())\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    loss = sum(losses) / len(losses)\n","    acc = correct / total\n","\n","    return loss, acc"],"metadata":{"id":"0422RfTQrxrS","executionInfo":{"status":"ok","timestamp":1735003742884,"user_tz":-420,"elapsed":5,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["train_losses, val_losses = fit(model, train_loader, val_loader, criterion, optimizer, device, epochs)"],"metadata":{"id":"RBmrutZ3sHY8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735004215613,"user_tz":-420,"elapsed":472733,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}},"outputId":"dddc5fb5-6a1a-4baf-bc95-5c42318bcb4e"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, train loss: 1.0717612101185707, val loss: 0.9923506796974497\n","Epoch 2/50, train loss: 0.9522027661723476, val loss: 0.9260871348921785\n","Epoch 3/50, train loss: 0.9284435741363033, val loss: 0.924053405978016\n","Epoch 4/50, train loss: 0.9257329894650367, val loss: 0.9236249512003869\n","Epoch 5/50, train loss: 0.9256860402322584, val loss: 0.9234840703993729\n","Epoch 6/50, train loss: 0.9278841922360082, val loss: 0.9231370023845398\n","Epoch 7/50, train loss: 0.9254538609135535, val loss: 0.9226802089779648\n","Epoch 8/50, train loss: 0.9307247361829204, val loss: 0.9222519108929585\n","Epoch 9/50, train loss: 0.9297684604121793, val loss: 0.9220819252053487\n","Epoch 10/50, train loss: 0.9212089892356626, val loss: 0.9219576058928499\n","Epoch 11/50, train loss: 0.9231208620532867, val loss: 0.9214286902516159\n","Epoch 12/50, train loss: 0.9229273853763458, val loss: 0.9216717859518897\n","Epoch 13/50, train loss: 0.9241092358866045, val loss: 0.9211549279616051\n","Epoch 14/50, train loss: 0.9196426368528797, val loss: 0.9198212113577066\n","Epoch 15/50, train loss: 0.9279039771326126, val loss: 0.9210705723344665\n","Epoch 16/50, train loss: 0.9213887126215042, val loss: 0.9196186747747598\n","Epoch 17/50, train loss: 0.9195750624902786, val loss: 0.9170943191371013\n","Epoch 18/50, train loss: 0.9165152388234292, val loss: 0.9157502466870338\n","Epoch 19/50, train loss: 0.9098385322478509, val loss: 0.9079562591523239\n","Epoch 20/50, train loss: 0.9030488517976576, val loss: 0.9014598745660684\n","Epoch 21/50, train loss: 0.8850635174782046, val loss: 0.9178210687391537\n","Epoch 22/50, train loss: 0.8801662806541689, val loss: 0.8845777689796133\n","Epoch 23/50, train loss: 0.870376956078314, val loss: 0.888452493652855\n","Epoch 24/50, train loss: 0.8511416412168934, val loss: 0.8928105112203618\n","Epoch 25/50, train loss: 0.8441545444150125, val loss: 0.8772889698289105\n","Epoch 26/50, train loss: 0.8346962294270915, val loss: 0.8723857365932661\n","Epoch 27/50, train loss: 0.8237931978317999, val loss: 0.8693195501553643\n","Epoch 28/50, train loss: 0.8225033936962005, val loss: 0.8653705034059348\n","Epoch 29/50, train loss: 0.8126764893531799, val loss: 0.873525716594814\n","Epoch 30/50, train loss: 0.8043580382100998, val loss: 0.867344115812754\n","Epoch 31/50, train loss: 0.7987818448774276, val loss: 0.864945392018741\n","Epoch 32/50, train loss: 0.7902577903962904, val loss: 0.8625413434407145\n","Epoch 33/50, train loss: 0.789295740665928, val loss: 0.8659808475946643\n","Epoch 34/50, train loss: 0.7789042399775598, val loss: 0.8720397979942793\n","Epoch 35/50, train loss: 0.7728783238318658, val loss: 0.8772588974421787\n","Epoch 36/50, train loss: 0.7622466048886699, val loss: 0.8709575705921527\n","Epoch 37/50, train loss: 0.7529747620705636, val loss: 0.8730276251576611\n","Epoch 38/50, train loss: 0.7493790022788509, val loss: 0.9098697212553516\n","Epoch 39/50, train loss: 0.7381192484209614, val loss: 0.872380793094635\n","Epoch 40/50, train loss: 0.7329801071074701, val loss: 0.8723511210421926\n","Epoch 41/50, train loss: 0.7236786350127189, val loss: 0.8710858846448132\n","Epoch 42/50, train loss: 0.7170431652376729, val loss: 0.8916435392247033\n","Epoch 43/50, train loss: 0.7093860699284461, val loss: 0.8621309494849333\n","Epoch 44/50, train loss: 0.7033277980742916, val loss: 0.8765764036743912\n","Epoch 45/50, train loss: 0.6955060958862305, val loss: 0.8942586503078028\n","Epoch 46/50, train loss: 0.6836410722424907, val loss: 0.8771539259817183\n","Epoch 47/50, train loss: 0.6740037164380474, val loss: 0.9001113124114951\n","Epoch 48/50, train loss: 0.6668392919724987, val loss: 0.8964614232176358\n","Epoch 49/50, train loss: 0.6528177194056972, val loss: 0.8931213153391769\n","Epoch 50/50, train loss: 0.6707897436234259, val loss: 0.8868538445418643\n"]}]},{"cell_type":"code","source":["val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n","test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n","\n","print(f'Val loss: {val_loss}, Val acc: {val_acc}')\n","print(f'Test loss: {test_loss}, Test acc: {test_acc}')"],"metadata":{"id":"OkVW5_bBw7Zh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735004216115,"user_tz":-420,"elapsed":504,"user":{"displayName":"Quân Bảo Nguyễn","userId":"07416800705691112885"}},"outputId":"5a5499bb-2ba5-4769-85c6-cc71c7e03d0e"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Val loss: 0.8868538445418643, Val acc: 0.6288659793814433\n","Test loss: 0.8647020983695984, Test acc: 0.6443298969072165\n"]}]}]}