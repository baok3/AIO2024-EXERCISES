{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46f5dca4c7594ef0847b11737b2da250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe14f7d62efa4c5abc5132d728766077",
              "IPY_MODEL_08b9d625f789485aa56fd0fa6d4d61e6",
              "IPY_MODEL_639d432648ef420ba241e767efbe7b8c"
            ],
            "layout": "IPY_MODEL_660cf27d1b7744f89368597a5e9541a6"
          }
        },
        "fe14f7d62efa4c5abc5132d728766077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab62efae6fbc489bb794f4665ab93f7c",
            "placeholder": "​",
            "style": "IPY_MODEL_f349a718fc7645e8b985160a8a4586c3",
            "value": "Map: 100%"
          }
        },
        "08b9d625f789485aa56fd0fa6d4d61e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f837e148f7e543b6b9356597b56a7f9c",
            "max": 1268,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d2161c144f5482ca9338f4be317c2e4",
            "value": 1268
          }
        },
        "639d432648ef420ba241e767efbe7b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de5f95be1ed4379828484bb3e7cfbf2",
            "placeholder": "​",
            "style": "IPY_MODEL_9d40cd8f6a0c48deae2d8efc77fa97bd",
            "value": " 1268/1268 [00:00&lt;00:00, 1799.96 examples/s]"
          }
        },
        "660cf27d1b7744f89368597a5e9541a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab62efae6fbc489bb794f4665ab93f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f349a718fc7645e8b985160a8a4586c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f837e148f7e543b6b9356597b56a7f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2161c144f5482ca9338f4be317c2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5de5f95be1ed4379828484bb3e7cfbf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d40cd8f6a0c48deae2d8efc77fa97bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:42:43.987181Z",
          "iopub.execute_input": "2025-02-25T10:42:43.987473Z",
          "iopub.status.idle": "2025-02-25T10:42:48.126329Z",
          "shell.execute_reply.started": "2025-02-25T10:42:43.987451Z",
          "shell.execute_reply": "2025-02-25T10:42:48.125192Z"
        },
        "id": "YWFh_yIS0YSi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"thainq107/iwslt2015-en-vi\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:42:48.691974Z",
          "iopub.execute_input": "2025-02-25T10:42:48.692297Z",
          "iopub.status.idle": "2025-02-25T10:42:57.308205Z",
          "shell.execute_reply.started": "2025-02-25T10:42:48.692270Z",
          "shell.execute_reply": "2025-02-25T10:42:57.307609Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq_cnI4p0YSj",
        "outputId": "5ece7f1e-8dee-45c0-fc6d-9c421d6a4257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:42:57.309075Z",
          "iopub.execute_input": "2025-02-25T10:42:57.309679Z",
          "iopub.status.idle": "2025-02-25T10:42:57.314269Z",
          "shell.execute_reply.started": "2025-02-25T10:42:57.309654Z",
          "shell.execute_reply": "2025-02-25T10:42:57.313599Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbKM2y8w0YSk",
        "outputId": "3f3c63a8-ee25-44a3-cf62-94713496e279"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['en', 'vi'],\n",
              "        num_rows: 133317\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['en', 'vi'],\n",
              "        num_rows: 1268\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['en', 'vi'],\n",
              "        num_rows: 1268\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'][0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:42:57.315757Z",
          "iopub.execute_input": "2025-02-25T10:42:57.316042Z",
          "iopub.status.idle": "2025-02-25T10:42:57.342078Z",
          "shell.execute_reply.started": "2025-02-25T10:42:57.316015Z",
          "shell.execute_reply": "2025-02-25T10:42:57.341485Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiXx22ce0YSl",
        "outputId": "07af56fe-2cac-4683-91e2-f8135ce4e553"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Rachel Pike : The science behind a climate headline',\n",
              " 'vi': 'Khoa học đằng sau một tiêu đề về khí hậu'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tokenizers import Tokenizer, pre_tokenizers, trainers, models\n",
        "\n",
        "# Tạo tokenizer dạng word-based\n",
        "tokenizer_en = Tokenizer(models.WordLevel(unk_token=\"<unk>\"))\n",
        "tokenizer_vi = Tokenizer(models.WordLevel(unk_token=\"<unk>\"))\n",
        "\n",
        "tokenizer_en.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "tokenizer_vi.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "trainer = trainers.WordLevelTrainer(\n",
        "    vocab_size=15000,\n",
        "    min_frequency=2,\n",
        "    special_tokens=[\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"]\n",
        ")\n",
        "\n",
        "# Huấn luyện tokenizer\n",
        "tokenizer_en.train_from_iterator(ds[\"train\"][\"en\"], trainer)\n",
        "tokenizer_vi.train_from_iterator(ds[\"train\"][\"vi\"], trainer)\n",
        "\n",
        "# Lưu tokenizer\n",
        "tokenizer_en.save(\"tokenizer_en.json\")\n",
        "tokenizer_vi.save(\"tokenizer_vi.json\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:43:01.240607Z",
          "iopub.execute_input": "2025-02-25T10:43:01.240913Z",
          "iopub.status.idle": "2025-02-25T10:43:04.101768Z",
          "shell.execute_reply.started": "2025-02-25T10:43:01.240890Z",
          "shell.execute_reply": "2025-02-25T10:43:04.100838Z"
        },
        "id": "CBZsOIwI0YSl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer_en.get_vocab()), len(tokenizer_vi.get_vocab())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:43:04.102908Z",
          "iopub.execute_input": "2025-02-25T10:43:04.103169Z",
          "iopub.status.idle": "2025-02-25T10:43:04.117774Z",
          "shell.execute_reply.started": "2025-02-25T10:43:04.103150Z",
          "shell.execute_reply": "2025-02-25T10:43:04.116805Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0QJru6d0YSm",
        "outputId": "8e632fe7-6df9-49d8-dd39-cff22885fb32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 13684)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.encode(\"how are you\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:43:08.025991Z",
          "iopub.execute_input": "2025-02-25T10:43:08.026259Z",
          "iopub.status.idle": "2025-02-25T10:43:08.031399Z",
          "shell.execute_reply.started": "2025-02-25T10:43:08.026238Z",
          "shell.execute_reply": "2025-02-25T10:43:08.030607Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzLyX15N0YSm",
        "outputId": "09328c62-b434-4f47-baa7-505204aa892d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=3, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.encode(\"how are you\").ids"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:43:12.991961Z",
          "iopub.execute_input": "2025-02-25T10:43:12.992241Z",
          "iopub.status.idle": "2025-02-25T10:43:12.997326Z",
          "shell.execute_reply.started": "2025-02-25T10:43:12.992221Z",
          "shell.execute_reply": "2025-02-25T10:43:12.996584Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMbDfQ3f0YSn",
        "outputId": "209fd981-f1dc-4c27-da66-a8ce37179654"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[81, 27, 18]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_vi.encode(\"bạn có khoẻ không\").ids"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:43:16.211952Z",
          "iopub.execute_input": "2025-02-25T10:43:16.212354Z",
          "iopub.status.idle": "2025-02-25T10:43:16.217686Z",
          "shell.execute_reply.started": "2025-02-25T10:43:16.212328Z",
          "shell.execute_reply": "2025-02-25T10:43:16.216899Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_yJAdKC0YSn",
        "outputId": "77db3a3c-8a59-45a0-c6ae-6f9c7cf40fea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18, 9, 596, 14]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "# Load tokenizer đã train vào PreTrainedTokenizerFast\n",
        "tokenizer_en = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"tokenizer_en.json\",\n",
        "    unk_token=\"<unk>\", pad_token=\"<pad>\", bos_token=\"<bos>\", eos_token=\"<eos>\"\n",
        ")\n",
        "tokenizer_vi = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"tokenizer_vi.json\",\n",
        "    unk_token=\"<unk>\", pad_token=\"<pad>\", bos_token=\"<bos>\", eos_token=\"<eos>\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:43:19.826156Z",
          "iopub.execute_input": "2025-02-25T10:43:19.826490Z",
          "iopub.status.idle": "2025-02-25T10:43:23.189324Z",
          "shell.execute_reply.started": "2025-02-25T10:43:19.826463Z",
          "shell.execute_reply": "2025-02-25T10:43:23.188448Z"
        },
        "id": "aT6bD5K30YSn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer_en), len(tokenizer_vi)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:43:28.379545Z",
          "iopub.execute_input": "2025-02-25T10:43:28.380056Z",
          "iopub.status.idle": "2025-02-25T10:43:28.391382Z",
          "shell.execute_reply.started": "2025-02-25T10:43:28.380026Z",
          "shell.execute_reply": "2025-02-25T10:43:28.390333Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTPda-iX0YSo",
        "outputId": "465fd62a-e3c3-4b5a-b9e8-1b0a823dcf73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 13684)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 75\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    src_texts = examples[\"en\"]\n",
        "    tgt_texts = [\"<bos>\" + sent + \"<eos>\" for sent in examples[\"vi\"]]\n",
        "\n",
        "    src_encodings = tokenizer_en(\n",
        "        src_texts, padding=\"max_length\", truncation=True, max_length=MAX_LEN\n",
        "    )\n",
        "    tgt_encodings = tokenizer_vi(\n",
        "        tgt_texts, padding=\"max_length\", truncation=True, max_length=MAX_LEN\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": src_encodings[\"input_ids\"],\n",
        "        \"labels\": tgt_encodings[\"input_ids\"],\n",
        "    }\n",
        "\n",
        "preprocessed_ds = ds.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:47:02.459689Z",
          "iopub.execute_input": "2025-02-25T10:47:02.459996Z",
          "iopub.status.idle": "2025-02-25T10:47:16.357236Z",
          "shell.execute_reply.started": "2025-02-25T10:47:02.459971Z",
          "shell.execute_reply": "2025-02-25T10:47:16.356570Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "46f5dca4c7594ef0847b11737b2da250",
            "fe14f7d62efa4c5abc5132d728766077",
            "08b9d625f789485aa56fd0fa6d4d61e6",
            "639d432648ef420ba241e767efbe7b8c",
            "660cf27d1b7744f89368597a5e9541a6",
            "ab62efae6fbc489bb794f4665ab93f7c",
            "f349a718fc7645e8b985160a8a4586c3",
            "f837e148f7e543b6b9356597b56a7f9c",
            "0d2161c144f5482ca9338f4be317c2e4",
            "5de5f95be1ed4379828484bb3e7cfbf2",
            "9d40cd8f6a0c48deae2d8efc77fa97bd"
          ]
        },
        "id": "jn9q7XWL0YSo",
        "outputId": "084349e4-5f39-4716-b81c-334c49917175"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1268 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46f5dca4c7594ef0847b11737b2da250"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_vi.unk_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:47:16.358216Z",
          "iopub.execute_input": "2025-02-25T10:47:16.358526Z",
          "iopub.status.idle": "2025-02-25T10:47:16.363155Z",
          "shell.execute_reply.started": "2025-02-25T10:47:16.358504Z",
          "shell.execute_reply": "2025-02-25T10:47:16.362337Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKHIT29l0YSo",
        "outputId": "39012b14-9d1b-4b5f-8883-df490974b9b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_vi.pad_token_id, tokenizer_vi.bos_token_id, tokenizer_vi.eos_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:47:16.364712Z",
          "iopub.execute_input": "2025-02-25T10:47:16.364994Z",
          "iopub.status.idle": "2025-02-25T10:47:16.921556Z",
          "shell.execute_reply.started": "2025-02-25T10:47:16.364969Z",
          "shell.execute_reply": "2025-02-25T10:47:16.920661Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tguVypSL0YSo",
        "outputId": "e59b7c17-7228-47bf-9b05-80b367989f7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_ds['train']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:47:19.354516Z",
          "iopub.execute_input": "2025-02-25T10:47:19.354819Z",
          "iopub.status.idle": "2025-02-25T10:47:19.359696Z",
          "shell.execute_reply.started": "2025-02-25T10:47:19.354797Z",
          "shell.execute_reply": "2025-02-25T10:47:19.358965Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jATJvAg0YSp",
        "outputId": "96f22708-ca14-42da-98e2-ce811b0cd4cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['en', 'vi', 'input_ids', 'labels'],\n",
              "    num_rows: 133317\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_ds['train'][0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:47:27.999916Z",
          "iopub.execute_input": "2025-02-25T10:47:28.000190Z",
          "iopub.status.idle": "2025-02-25T10:47:28.005357Z",
          "shell.execute_reply.started": "2025-02-25T10:47:28.000170Z",
          "shell.execute_reply": "2025-02-25T10:47:28.004618Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XcM-Cyq0YSp",
        "outputId": "32c276b8-8e8d-4f51-ebc6-307c12830f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'en': 'Rachel Pike : The science behind a climate headline', 'vi': 'Khoa học đằng sau một tiêu đề về khí hậu', 'input_ids': [6675, 1, 57, 60, 339, 604, 13, 744, 5643, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [2, 1960, 66, 1157, 131, 8, 376, 113, 38, 417, 735, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import PreTrainedModel, PretrainedConfig\n",
        "\n",
        "class Seq2SeqRNNConfig(PretrainedConfig):\n",
        "    def __init__(self,\n",
        "                 vocab_size_src=10000, vocab_size_tgt=10000,\n",
        "                 embedding_dim=128, hidden_size=128, dropout=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocab_size_src = vocab_size_src\n",
        "        self.vocab_size_tgt = vocab_size_tgt\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = dropout\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))  # B x S x H\n",
        "        output, hidden = self.gru(embedded)  # B x S x H, B x H\n",
        "        return output, hidden\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding_dim, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)  # LM Head\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)  # B x 1 x Vocab\n",
        "        return output, hidden\n",
        "\n",
        "class Seq2SeqRNNModel(PreTrainedModel):\n",
        "    config_class = Seq2SeqRNNConfig\n",
        "\n",
        "    def __init__(self, config, tokenizer_en):\n",
        "        super().__init__(config)\n",
        "        self.encoder = EncoderRNN(\n",
        "            config.vocab_size_src, config.embedding_dim,\n",
        "            config.hidden_size, config.dropout)\n",
        "        self.decoder = DecoderRNN(\n",
        "            config.hidden_size, config.embedding_dim, config.vocab_size_tgt)\n",
        "        self.BOS_IDX = tokenizer_en.bos_token_id\n",
        "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=0)  # Ignore PAD Token\n",
        "\n",
        "    def forward(self, input_ids, labels):\n",
        "        ### Your Code Here\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:47:34.988467Z",
          "iopub.execute_input": "2025-02-25T10:47:34.988770Z",
          "iopub.status.idle": "2025-02-25T10:47:50.221919Z",
          "shell.execute_reply.started": "2025-02-25T10:47:34.988749Z",
          "shell.execute_reply": "2025-02-25T10:47:50.220972Z"
        },
        "id": "iAODDKuL0YSp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "config = Seq2SeqRNNConfig(\n",
        "    vocab_size_src=len(tokenizer_en), vocab_size_tgt=len(tokenizer_vi)\n",
        ")\n",
        "model = Seq2SeqRNNModel(config, tokenizer_en)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:47:50.223217Z",
          "iopub.execute_input": "2025-02-25T10:47:50.223863Z",
          "iopub.status.idle": "2025-02-25T10:47:50.304022Z",
          "shell.execute_reply.started": "2025-02-25T10:47:50.223839Z",
          "shell.execute_reply": "2025-02-25T10:47:50.303253Z"
        },
        "id": "EdwRofYD0YSp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:47:50.305156Z",
          "iopub.execute_input": "2025-02-25T10:47:50.305441Z",
          "iopub.status.idle": "2025-02-25T10:47:50.310163Z",
          "shell.execute_reply.started": "2025-02-25T10:47:50.305399Z",
          "shell.execute_reply": "2025-02-25T10:47:50.309324Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHMre_Pf0YSp",
        "outputId": "a716c715-dde7-4e6d-d13e-b6efb7291c27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqRNNModel(\n",
              "  (encoder): EncoderRNN(\n",
              "    (embedding): Embedding(15000, 128)\n",
              "    (gru): GRU(128, 128, batch_first=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): DecoderRNN(\n",
              "    (embedding): Embedding(13684, 128)\n",
              "    (gru): GRU(128, 128, batch_first=True)\n",
              "    (out): Linear(in_features=128, out_features=13684, bias=True)\n",
              "  )\n",
              "  (loss_fn): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import PreTrainedModel, PretrainedConfig\n",
        "\n",
        "def generate_square_subsequent_mask(sz, device):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[1]\n",
        "    tgt_seq_len = tgt.shape[1]\n",
        "    device = src.device\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device).to(torch.bool)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
        "    src_padding_mask = (src == 0)\n",
        "    tgt_padding_mask = (tgt == 0)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
        "\n",
        "class Seq2SeqTransformerConfig(PretrainedConfig):\n",
        "    def __init__(\n",
        "            self, vocab_size_src=10000, vocab_size_tgt=10000, max_seq_length=50,\n",
        "            d_model=256, num_heads=8, num_layers=6, dropout=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocab_size_src = vocab_size_src\n",
        "        self.vocab_size_tgt = vocab_size_tgt\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "class Seq2SeqTransformerModel(PreTrainedModel):\n",
        "    config_class = Seq2SeqTransformerConfig\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.embedding_src = nn.Embedding(\n",
        "            config.vocab_size_src, config.d_model)\n",
        "        self.embedding_tgt = nn.Embedding(\n",
        "            config.vocab_size_tgt, config.d_model)\n",
        "\n",
        "        self.position_embedding_src = nn.Embedding(\n",
        "            config.max_seq_length, config.d_model)\n",
        "        self.position_embedding_tgt = nn.Embedding(\n",
        "            config.max_seq_length, config.d_model)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=config.d_model,\n",
        "            nhead=config.num_heads,\n",
        "            num_encoder_layers=config.num_layers,\n",
        "            num_decoder_layers=config.num_layers,\n",
        "            dropout=config.dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.generator = nn.Linear(\n",
        "            config.d_model, config.vocab_size_tgt\n",
        "            )\n",
        "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=0)  # Ignore PAD token\n",
        "\n",
        "    def forward(self, input_ids, labels):\n",
        "        tgt_input = labels[:, :-1]\n",
        "        tgt_output = labels[:, 1:]\n",
        "        batch_size, seq_len_src = input_ids.shape\n",
        "        _, seq_len_tgt = tgt_input.shape\n",
        "\n",
        "        src_positions = torch.arange(seq_len_src, device=input_ids.device).unsqueeze(0)\n",
        "        tgt_positions = torch.arange(seq_len_tgt, device=labels.device).unsqueeze(0)\n",
        "\n",
        "        src_embedded = self.embedding_src(input_ids) + self.position_embedding_src(src_positions)\n",
        "        tgt_embedded = self.embedding_tgt(tgt_input) + self.position_embedding_tgt(tgt_positions)\n",
        "\n",
        "        src_mask, tgt_mask, src_key_padding_mask, tgt_key_padding_mask = create_mask(input_ids, tgt_input)\n",
        "\n",
        "        outs = self.transformer(\n",
        "            src_embedded, tgt_embedded, src_mask, tgt_mask,\n",
        "            src_key_padding_mask=src_key_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask\n",
        "        )\n",
        "\n",
        "        logits = self.generator(outs)\n",
        "        loss = self.loss_fn(logits.permute(0, 2, 1), tgt_output)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        _, seq_len_src = src.shape\n",
        "        src_positions = torch.arange(\n",
        "            seq_len_src, device=src.device).unsqueeze(0)\n",
        "        src_embedded = self.embedding_src(src) + self.position_embedding_src(\n",
        "            src_positions)\n",
        "        return self.transformer.encoder(src_embedded, src_mask)\n",
        "\n",
        "    def decode(self, tgt, encoder_output, tgt_mask):\n",
        "        _, seq_len_tgt = tgt.shape\n",
        "        tgt_positions = torch.arange(\n",
        "            seq_len_tgt, device=tgt.device).unsqueeze(0)\n",
        "        tgt_embedded = self.embedding_tgt(tgt) + self.position_embedding_tgt(\n",
        "            tgt_positions)\n",
        "        return self.transformer.decoder(\n",
        "            tgt_embedded, encoder_output, tgt_mask\n",
        "        )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:47:57.550841Z",
          "iopub.execute_input": "2025-02-25T10:47:57.551113Z",
          "iopub.status.idle": "2025-02-25T10:47:57.563258Z",
          "shell.execute_reply.started": "2025-02-25T10:47:57.551093Z",
          "shell.execute_reply": "2025-02-25T10:47:57.562519Z"
        },
        "id": "-hhnb4rm0YSp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo config\n",
        "config = Seq2SeqTransformerConfig(\n",
        "    vocab_size_src=len(tokenizer_en), vocab_size_tgt=len(tokenizer_vi), max_seq_length=75\n",
        ")\n",
        "\n",
        "# Tạo mô hình\n",
        "model = Seq2SeqTransformerModel(config)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:48:03.005111Z",
          "iopub.execute_input": "2025-02-25T10:48:03.005410Z",
          "iopub.status.idle": "2025-02-25T10:48:03.288697Z",
          "shell.execute_reply.started": "2025-02-25T10:48:03.005388Z",
          "shell.execute_reply": "2025-02-25T10:48:03.288000Z"
        },
        "id": "KQBPM0N20YSq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:48:11.374402Z",
          "iopub.execute_input": "2025-02-25T10:48:11.374728Z",
          "iopub.status.idle": "2025-02-25T10:48:11.380495Z",
          "shell.execute_reply.started": "2025-02-25T10:48:11.374703Z",
          "shell.execute_reply": "2025-02-25T10:48:11.379774Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koEEO3en0YSq",
        "outputId": "aa5476fe-05c8-4179-a107-10a84874717b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTransformerModel(\n",
              "  (embedding_src): Embedding(15000, 256)\n",
              "  (embedding_tgt): Embedding(13684, 256)\n",
              "  (position_embedding_src): Embedding(75, 256)\n",
              "  (position_embedding_tgt): Embedding(75, 256)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (generator): Linear(in_features=256, out_features=13684, bias=True)\n",
              "  (loss_fn): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([preprocessed_ds['train'][0]['input_ids']])\n",
        "labels = torch.tensor([preprocessed_ds['train'][0]['labels']])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:48:15.690012Z",
          "iopub.execute_input": "2025-02-25T10:48:15.690313Z",
          "iopub.status.idle": "2025-02-25T10:48:15.697556Z",
          "shell.execute_reply.started": "2025-02-25T10:48:15.690284Z",
          "shell.execute_reply": "2025-02-25T10:48:15.696710Z"
        },
        "id": "M2YgGWQl0YSq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:48:20.154140Z",
          "iopub.execute_input": "2025-02-25T10:48:20.154590Z",
          "iopub.status.idle": "2025-02-25T10:48:20.175054Z",
          "shell.execute_reply.started": "2025-02-25T10:48:20.154552Z",
          "shell.execute_reply": "2025-02-25T10:48:20.174164Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_FrxiiC0YSq",
        "outputId": "3622f5db-fc3a-4205-9e48-1df53efe06b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6675,    1,   57,   60,  339,  604,   13,  744, 5643,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:48:24.436861Z",
          "iopub.execute_input": "2025-02-25T10:48:24.437168Z",
          "iopub.status.idle": "2025-02-25T10:48:24.442732Z",
          "shell.execute_reply.started": "2025-02-25T10:48:24.437142Z",
          "shell.execute_reply": "2025-02-25T10:48:24.442067Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AToRJKB0YSq",
        "outputId": "4e431957-dbb1-4613-f01d-b4af127137aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   2, 1960,   66, 1157,  131,    8,  376,  113,   38,  417,  735,    3,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(input_ids, labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:48:27.562504Z",
          "iopub.execute_input": "2025-02-25T10:48:27.562800Z",
          "iopub.status.idle": "2025-02-25T10:48:27.742847Z",
          "shell.execute_reply.started": "2025-02-25T10:48:27.562777Z",
          "shell.execute_reply": "2025-02-25T10:48:27.741950Z"
        },
        "id": "FCGH-him0YSq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T10:48:31.705943Z",
          "iopub.execute_input": "2025-02-25T10:48:31.706254Z",
          "iopub.status.idle": "2025-02-25T10:48:31.724326Z",
          "shell.execute_reply.started": "2025-02-25T10:48:31.706227Z",
          "shell.execute_reply": "2025-02-25T10:48:31.723503Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPR5PLGM0YSq",
        "outputId": "219c6b02-fc24-4b8b-aa80-8cd051db8c0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': tensor(9.6727, grad_fn=<NllLoss2DBackward0>),\n",
              " 'logits': tensor([[[ 0.5441,  0.6833,  0.3662,  ...,  0.6054,  0.2984, -0.2827],\n",
              "          [ 0.3388,  1.0597, -0.3598,  ...,  0.2879,  0.4700,  0.2904],\n",
              "          [ 0.0558,  0.2915, -0.6704,  ...,  0.1686, -0.2942,  0.5129],\n",
              "          ...,\n",
              "          [-0.3916,  0.8364, -0.6244,  ...,  0.2229,  0.2870,  0.7027],\n",
              "          [-0.5751,  0.5617,  0.1047,  ..., -0.4309, -0.1620,  0.6508],\n",
              "          [-0.1384,  1.0049, -0.4755,  ...,  0.2064,  0.1769,  1.0981]]],\n",
              "        grad_fn=<ViewBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init(\n",
        "     project=\"en-vi-machine-translation\",\n",
        "     name=\"transformer\" # \"gru\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T11:07:38.408487Z",
          "iopub.execute_input": "2025-02-25T11:07:38.408823Z",
          "iopub.status.idle": "2025-02-25T11:07:38.412466Z",
          "shell.execute_reply.started": "2025-02-25T11:07:38.408797Z",
          "shell.execute_reply": "2025-02-25T11:07:38.411648Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "WbpcFaWg0YSq",
        "outputId": "18a8b974-9638-447f-cf98-7b15d185de96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquanbaonguyen03\u001b[0m (\u001b[33mquanbao\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250225_112238-czvyfh7h</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/quanbao/en-vi-machine-translation/runs/czvyfh7h' target=\"_blank\">transformer</a></strong> to <a href='https://wandb.ai/quanbao/en-vi-machine-translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/quanbao/en-vi-machine-translation' target=\"_blank\">https://wandb.ai/quanbao/en-vi-machine-translation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/quanbao/en-vi-machine-translation/runs/czvyfh7h' target=\"_blank\">https://wandb.ai/quanbao/en-vi-machine-translation/runs/czvyfh7h</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/quanbao/en-vi-machine-translation/runs/czvyfh7h?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7aa7fffa9f10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Cấu hình training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./en-vi-machine-translation\",\n",
        "    logging_dir=\"logs\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=512,\n",
        "    per_device_eval_batch_size=512,\n",
        "    num_train_epochs=25,\n",
        "    learning_rate=2e-5,\n",
        "    save_total_limit=1,\n",
        "    report_to=\"wandb\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=preprocessed_ds[\"train\"],\n",
        "    eval_dataset=preprocessed_ds[\"validation\"]\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T11:07:55.574920Z",
          "iopub.execute_input": "2025-02-25T11:07:55.575206Z",
          "iopub.status.idle": "2025-02-25T11:07:55.613765Z",
          "shell.execute_reply.started": "2025-02-25T11:07:55.575185Z",
          "shell.execute_reply": "2025-02-25T11:07:55.612899Z"
        },
        "id": "lxuIa7Us0YSq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-25T11:08:02.850503Z",
          "iopub.execute_input": "2025-02-25T11:08:02.850832Z",
          "iopub.status.idle": "2025-02-25T11:08:04.002118Z",
          "shell.execute_reply.started": "2025-02-25T11:08:02.850806Z",
          "shell.execute_reply": "2025-02-25T11:08:04.000749Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "rhOo-Y0Q0YSr",
        "outputId": "48cdfa96-a151-4ecf-df4d-c260d6745313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquanbaonguyen03\u001b[0m (\u001b[33mquanbao\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250225_112609-z9jlg5k6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/quanbao/huggingface/runs/z9jlg5k6' target=\"_blank\">./en-vi-machine-translation</a></strong> to <a href='https://wandb.ai/quanbao/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/quanbao/huggingface' target=\"_blank\">https://wandb.ai/quanbao/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/quanbao/huggingface/runs/z9jlg5k6' target=\"_blank\">https://wandb.ai/quanbao/huggingface/runs/z9jlg5k6</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol, device=\"cpu\"):\n",
        "    src = src.to(device)\n",
        "    src_mask = src_mask.to(device)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(device)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(1), device)\n",
        "                    .type(torch.bool)).to(device)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        prob = model.generator(out[:,-1, :])  # LM Head\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word[-1].item()  # index\n",
        "\n",
        "        ys = torch.cat([ys, torch.ones(1, 1).type_as(\n",
        "            src.data).fill_(next_word)], dim=1)\n",
        "        if next_word == 3:  # EOS : 3\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "def translate(model, src_sentence, device):\n",
        "    model.eval()\n",
        "    input_ids = tokenizer_en([src_sentence], return_tensors='pt')['input_ids'].to(device)\n",
        "    num_tokens = input_ids.shape[1]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(device)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model, input_ids, src_mask, max_len=num_tokens + 5, start_symbol=2, device=device)\n",
        "    return tokenizer_vi.decode(a.detach().cpu()[0])\n",
        "\n",
        "translate(model, \"i go to school\", model.device)  # => toi den truong"
      ],
      "metadata": {
        "trusted": true,
        "id": "ebyWPs5U0YSr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sacrebleu==2.5.1"
      ],
      "metadata": {
        "id": "xq0znfIt4-ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on test set\n",
        "from tqdm import tqdm\n",
        "import sacrebleu\n",
        "\n",
        "pred_sentences, tgt_sentences = [], []\n",
        "for sample in tqdm(ds['test']):\n",
        "    src_sentence = sample['en']\n",
        "    tgt_sentence = sample['vi']\n",
        "\n",
        "    pred_sentence = translate(model, src_sentence)\n",
        "    pred_sentences.append(pred_sentence)\n",
        "\n",
        "    tgt_sentences.append(tgt_sentence)\n",
        "\n",
        "bleu_score = sacrebleu.corpus_bleu(pred_sentences, [tgt_sentences], force=True)"
      ],
      "metadata": {
        "id": "NuyIIhTg48_x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}