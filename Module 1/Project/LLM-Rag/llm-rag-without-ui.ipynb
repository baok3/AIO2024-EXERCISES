{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8893738,"sourceType":"datasetVersion","datasetId":5348306}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -q transformers\n! pip install -q bitsandbytes\n! pip install -q accelerate\n! pip install -q langchain\n! pip install -q langchainhub\n! pip install -q langchain-chroma\n! pip install -q langchain-community\n! pip install -q langchain_huggingface\n! pip install -q python-dotenv\n! pip install -q pypdf\n! pip install -q numpy\n! pip install -q chainlit","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-07T08:34:37.185797Z","iopub.execute_input":"2024-07-07T08:34:37.186116Z","iopub.status.idle":"2024-07-07T08:37:18.217224Z","shell.execute_reply.started":"2024-07-07T08:34:37.186091Z","shell.execute_reply":"2024-07-07T08:37:18.215970Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nopentelemetry-instrumentation-asgi 0.43b0 requires opentelemetry-instrumentation==0.43b0, but you have opentelemetry-instrumentation 0.46b0 which is incompatible.\nopentelemetry-instrumentation-asgi 0.43b0 requires opentelemetry-semantic-conventions==0.43b0, but you have opentelemetry-semantic-conventions 0.46b0 which is incompatible.\nopentelemetry-instrumentation-fastapi 0.43b0 requires opentelemetry-instrumentation==0.43b0, but you have opentelemetry-instrumentation 0.46b0 which is incompatible.\nopentelemetry-instrumentation-fastapi 0.43b0 requires opentelemetry-semantic-conventions==0.43b0, but you have opentelemetry-semantic-conventions 0.46b0 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nypy-websocket 0.8.4 requires aiofiles<23,>=22.1.0, but you have aiofiles 23.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import chainlit as cl\nimport torch\n\nfrom chainlit.types import AskFileResponse\n\nfrom transformers import BitsAndBytesConfig\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain_huggingface.llms import HuggingFacePipeline\n\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_community.document_loaders import PyPDFLoader, TextLoader\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain_chroma import Chroma\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain import hub","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:13:08.546665Z","iopub.execute_input":"2024-07-07T09:13:08.547325Z","iopub.status.idle":"2024-07-07T09:13:08.554023Z","shell.execute_reply.started":"2024-07-07T09:13:08.547284Z","shell.execute_reply":"2024-07-07T09:13:08.552920Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"Loader = PyPDFLoader\nFILE_PATH = \"/kaggle/input/yolo-10-tutorial/YOLOv10_Tutorials.pdf\"\nloader = Loader(FILE_PATH)\ndocuments = loader.load()\n\nprint(\"Number of documents: \", len(documents))\ndocuments[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:15:48.282522Z","iopub.execute_input":"2024-07-07T09:15:48.282912Z","iopub.status.idle":"2024-07-07T09:15:49.090797Z","shell.execute_reply.started":"2024-07-07T09:15:48.282880Z","shell.execute_reply":"2024-07-07T09:15:49.089833Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Number of documents:  20\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Document(metadata={'source': '/kaggle/input/yolo-10-tutorial/YOLOv10_Tutorials.pdf', 'page': 0}, page_content='AI VIET NAM – AI COURSE 2024\\nTutorial: Phát hiện đối tượng trong ảnh với\\nYOLOv10\\nDinh-Thang Duong, Nguyen-Thuan Duong, Minh-Duc Bui và\\nQuang-Vinh Dinh\\nNgày 20 tháng 6 năm 2024\\nI. Giới thiệu\\nObject Detection (Tạm dịch: Phát hiện đối tượng) là một bài toán cổ điển thuộc lĩnh vực\\nComputer Vision. Mục tiêu của bài toán này là tự động xác định vị trí của các đối tượng trong\\nmột tấm ảnh. Tính tới thời điểm hiện tại, đã có rất nhiều phương pháp được phát triển nhằm\\ngiải quyết hiệu quả bài toán này. Trong đó, các phương pháp thuộc họ YOLO (You Only Look\\nOnce) thu hút được sự chú ý rất lớn từ cộng đồng nghiên cứu bởi độ chính xác và tốc độ thực\\nthi mà loại mô hình này mang lại.\\nHình 1: Logo của mô hình YOLO. Ảnh: link.\\nThời gian vừa qua, Ao Wang và các cộng sự tại Đại học Thanh Hoa (Tsinghua University)\\nđã đề xuất mô hình YOLOv10 trong bài báo YOLOv10: Real-Time End-to-End Object\\nDetection [10]. Với những cải tiến mới, mô hình đã đạt được hiệu suất vượt trội hơn so với các\\nphiên bản YOLO trước đó ở các khía cạnh khác nhau, tăng cường khả năng phát hiện đối tượng\\ntheo thời gian thực (real-time object detection).\\n1')"},"metadata":{}}]},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n                                               chunk_overlap=100)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:16:12.113144Z","iopub.execute_input":"2024-07-07T09:16:12.113468Z","iopub.status.idle":"2024-07-07T09:16:12.117697Z","shell.execute_reply.started":"2024-07-07T09:16:12.113439Z","shell.execute_reply":"2024-07-07T09:16:12.116705Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"docs = text_splitter.split_documents(documents)\n\nprint(\"Number of mini-documents: \", len(docs))\ndocs[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:16:15.058938Z","iopub.execute_input":"2024-07-07T09:16:15.059294Z","iopub.status.idle":"2024-07-07T09:16:15.068628Z","shell.execute_reply.started":"2024-07-07T09:16:15.059264Z","shell.execute_reply":"2024-07-07T09:16:15.067685Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Number of mini-documents:  33\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Document(metadata={'source': '/kaggle/input/yolo-10-tutorial/YOLOv10_Tutorials.pdf', 'page': 0}, page_content='AI VIET NAM – AI COURSE 2024\\nTutorial: Phát hiện đối tượng trong ảnh với\\nYOLOv10\\nDinh-Thang Duong, Nguyen-Thuan Duong, Minh-Duc Bui và\\nQuang-Vinh Dinh\\nNgày 20 tháng 6 năm 2024\\nI. Giới thiệu\\nObject Detection (Tạm dịch: Phát hiện đối tượng) là một bài toán cổ điển thuộc lĩnh vực\\nComputer Vision. Mục tiêu của bài toán này là tự động xác định vị trí của các đối tượng trong\\nmột tấm ảnh. Tính tới thời điểm hiện tại, đã có rất nhiều phương pháp được phát triển nhằm\\ngiải quyết hiệu quả bài toán này. Trong đó, các phương pháp thuộc họ YOLO (You Only Look\\nOnce) thu hút được sự chú ý rất lớn từ cộng đồng nghiên cứu bởi độ chính xác và tốc độ thực\\nthi mà loại mô hình này mang lại.\\nHình 1: Logo của mô hình YOLO. Ảnh: link.\\nThời gian vừa qua, Ao Wang và các cộng sự tại Đại học Thanh Hoa (Tsinghua University)\\nđã đề xuất mô hình YOLOv10 trong bài báo YOLOv10: Real-Time End-to-End Object\\nDetection [10]. Với những cải tiến mới, mô hình đã đạt được hiệu suất vượt trội hơn so với các')"},"metadata":{}}]},{"cell_type":"code","source":"embedding = HuggingFaceEmbeddings()","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:16:26.130395Z","iopub.execute_input":"2024-07-07T09:16:26.130778Z","iopub.status.idle":"2024-07-07T09:16:27.657629Z","shell.execute_reply.started":"2024-07-07T09:16:26.130747Z","shell.execute_reply":"2024-07-07T09:16:27.656796Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"vector_db = Chroma.from_documents(documents=docs,\n                                  embedding=embedding)\n\nretriever = vector_db.as_retriever()\n\nQUERY = \"YOLOv10 là gì\"\nresult = retriever.invoke(QUERY)\n\nprint(\"Number of relevant documents: \", len(result))\nresult[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:16:55.451033Z","iopub.execute_input":"2024-07-07T09:16:55.451312Z","iopub.status.idle":"2024-07-07T09:16:56.248514Z","shell.execute_reply.started":"2024-07-07T09:16:55.451288Z","shell.execute_reply":"2024-07-07T09:16:56.247681Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Number of relevant documents:  4\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"Document(metadata={'page': 15, 'source': '/kaggle/input/yolo-10-tutorial/YOLOv10_Tutorials.pdf'}, page_content='AI VIETNAM (AIO2024) aivietnam.edu.vn\\n1! mkdir datasets\\n2! unzip -q \"/ content / PlantDocv4 . zip\" -d \"/ content / datasets / PlantDocv4\\n/\"\\n3!rm / content / PlantDocv4 .zip\\nQuan sát thư mục giải nén, có thể thấy bộ dữ liệu này đã được gán nhãn và đưa vào format\\ncấu trúc dữ liệu training theo yêu cầu của YOLO. Vì vậy, chúng ta sẽ không cần thực hiện\\nbước chuẩn bị dữ liệu ở bài này.\\n2.Cài đặt và import các thư viện cần thiết: Tương tự như phần trước, các bạn chạy\\ncác đoạn code sau để cài đặt các gói thư viện để sử dụng được YOLOv10:\\n1!git clone https :// github .com/THU -MIG/ yolov10 .git\\n2%cd yolov10\\n3!pip install -q -r requirements .txt\\n4!pip install -e .\\n3.Khởi tạo mô hình YOLOv10: Chúng ta sẽ khởi tạo mộ hình YOLOv10 với phiên\\nbảnnano (n) từ trọng số đã được huấn luyện trên bộ dữ liệu COCO. Để tải trọng số\\nyolov10n.pt, các bạn chạy đoạn code sau:\\n1! wget https :// github .com/THU -MIG/ yolov10 / releases / download /v1 .1/\\nyolov10n .pt')"},"metadata":{}}]},{"cell_type":"code","source":"nf4_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nMODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=nf4_config,\n    low_cpu_mem_usage=True\n)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\nmodel_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=512,\n    pad_token_id=tokenizer.eos_token_id,\n    device_map=\"auto\"\n)\n\nllm = HuggingFacePipeline(\n    pipeline=model_pipeline,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:17:12.582195Z","iopub.execute_input":"2024-07-07T09:17:12.582573Z","iopub.status.idle":"2024-07-07T09:17:20.126859Z","shell.execute_reply.started":"2024-07-07T09:17:12.582541Z","shell.execute_reply":"2024-07-07T09:17:20.126025Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ed71a71d2bf4c418845e73b035b4449"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = hub.pull(\"rlm/rag-prompt\")\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nUSER_QUESTION = \"YOLOv10 là gì?\"\noutput = rag_chain.invoke(USER_QUESTION)\noutput","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:17:37.043080Z","iopub.execute_input":"2024-07-07T09:17:37.043449Z","iopub.status.idle":"2024-07-07T09:17:58.742515Z","shell.execute_reply.started":"2024-07-07T09:17:37.043415Z","shell.execute_reply":"2024-07-07T09:17:58.741550Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: YOLOv10 là gì? \\nContext: 2.Tải trọng số của pre-trained models: Để sử dụng được pre-trained models, chúng ta\\ncần tải về file trọng số (file .pt). Các bạn chạy đoạn code sau để tải về file trọng số phiên\\nbản YOLOv10n:\\n1! wget https :// github .com/THU -MIG/ yolov10 / releases / download /v1 .1/\\nyolov10n .pt\\n3.Khởi tạo mô hình: Để khởi tạo mô hình với trọng số vừa tải về, các bạn chạy đoạn code\\nsau:\\n1from ultralytics import YOLOv10\\n2\\n3model = YOLOv10 (\" yolov10n .pt\")\\n4.Tải ảnh cần dự đoán: Chúng ta sẽ test mô hình trên một ảnh bất kì. Các bạn có thể tự\\nchọn ảnh của riêng mình hoặc sử dụng ảnh tại đây. Các bạn có thể chạy đoạn code sau để\\ntải ảnh này vào colab tự động:\\n1! gdown \"1 tr9PSRRdlC2pNir7jsYugpSMG -7 v32VJ \" -O \"./ images /\"\\n13\\n\\n2.Tải trọng số của pre-trained models: Để sử dụng được pre-trained models, chúng ta\\ncần tải về file trọng số (file .pt). Các bạn chạy đoạn code sau để tải về file trọng số phiên\\nbản YOLOv10n:\\n1! wget https :// github .com/THU -MIG/ yolov10 / releases / download /v1 .1/\\nyolov10n .pt\\n3.Khởi tạo mô hình: Để khởi tạo mô hình với trọng số vừa tải về, các bạn chạy đoạn code\\nsau:\\n1from ultralytics import YOLOv10\\n2\\n3model = YOLOv10 (\" yolov10n .pt\")\\n4.Tải ảnh cần dự đoán: Chúng ta sẽ test mô hình trên một ảnh bất kì. Các bạn có thể tự\\nchọn ảnh của riêng mình hoặc sử dụng ảnh tại đây. Các bạn có thể chạy đoạn code sau để\\ntải ảnh này vào colab tự động:\\n1! gdown \"1 tr9PSRRdlC2pNir7jsYugpSMG -7 v32VJ \" -O \"./ images /\"\\n13\\n\\nAI VIETNAM (AIO2024) aivietnam.edu.vn\\n1! mkdir datasets\\n2! unzip -q \"/ content / PlantDocv4 . zip\" -d \"/ content / datasets / PlantDocv4\\n/\"\\n3!rm / content / PlantDocv4 .zip\\nQuan sát thư mục giải nén, có thể thấy bộ dữ liệu này đã được gán nhãn và đưa vào format\\ncấu trúc dữ liệu training theo yêu cầu của YOLO. Vì vậy, chúng ta sẽ không cần thực hiện\\nbước chuẩn bị dữ liệu ở bài này.\\n2.Cài đặt và import các thư viện cần thiết: Tương tự như phần trước, các bạn chạy\\ncác đoạn code sau để cài đặt các gói thư viện để sử dụng được YOLOv10:\\n1!git clone https :// github .com/THU -MIG/ yolov10 .git\\n2%cd yolov10\\n3!pip install -q -r requirements .txt\\n4!pip install -e .\\n3.Khởi tạo mô hình YOLOv10: Chúng ta sẽ khởi tạo mộ hình YOLOv10 với phiên\\nbảnnano (n) từ trọng số đã được huấn luyện trên bộ dữ liệu COCO. Để tải trọng số\\nyolov10n.pt, các bạn chạy đoạn code sau:\\n1! wget https :// github .com/THU -MIG/ yolov10 / releases / download /v1 .1/\\nyolov10n .pt\\n\\nAI VIETNAM (AIO2024) aivietnam.edu.vn\\n1! mkdir datasets\\n2! unzip -q \"/ content / PlantDocv4 . zip\" -d \"/ content / datasets / PlantDocv4\\n/\"\\n3!rm / content / PlantDocv4 .zip\\nQuan sát thư mục giải nén, có thể thấy bộ dữ liệu này đã được gán nhãn và đưa vào format\\ncấu trúc dữ liệu training theo yêu cầu của YOLO. Vì vậy, chúng ta sẽ không cần thực hiện\\nbước chuẩn bị dữ liệu ở bài này.\\n2.Cài đặt và import các thư viện cần thiết: Tương tự như phần trước, các bạn chạy\\ncác đoạn code sau để cài đặt các gói thư viện để sử dụng được YOLOv10:\\n1!git clone https :// github .com/THU -MIG/ yolov10 .git\\n2%cd yolov10\\n3!pip install -q -r requirements .txt\\n4!pip install -e .\\n3.Khởi tạo mô hình YOLOv10: Chúng ta sẽ khởi tạo mộ hình YOLOv10 với phiên\\nbảnnano (n) từ trọng số đã được huấn luyện trên bộ dữ liệu COCO. Để tải trọng số\\nyolov10n.pt, các bạn chạy đoạn code sau:\\n1! wget https :// github .com/THU -MIG/ yolov10 / releases / download /v1 .1/\\nyolov10n .pt \\nAnswer: YOLOv10 là một phiên bản của mô hình máy học dự đoán hình ảnh được phát triển bởi Ultralytics. Nó được huấn luyện trên bộ dữ liệu COCO và có thể được sử dụng để dự đoán các hình ảnh mới.'"},"metadata":{}}]},{"cell_type":"code","source":"answer = output.split('Answer:')[1].strip()\nanswer","metadata":{"execution":{"iopub.status.busy":"2024-07-07T09:19:04.804227Z","iopub.execute_input":"2024-07-07T09:19:04.804620Z","iopub.status.idle":"2024-07-07T09:19:04.810918Z","shell.execute_reply.started":"2024-07-07T09:19:04.804588Z","shell.execute_reply":"2024-07-07T09:19:04.810020Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'YOLOv10 là một phiên bản của mô hình máy học dự đoán hình ảnh được phát triển bởi Ultralytics. Nó được huấn luyện trên bộ dữ liệu COCO và có thể được sử dụng để dự đoán các hình ảnh mới.'"},"metadata":{}}]}]}