{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  torch import nn\n",
    "import mediapipe as mp\n",
    "from torch import optim\n",
    "from datetime import datetime\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data2/landmark_train.csv already exists, skipping download\n",
      "data2/landmark_test.csv already exists, skipping download\n",
      "data2/landmark_val.csv already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Mapping of Google Drive file IDs to desired filenames\n",
    "file_mapping = {\n",
    "    '1gzWOtABiVmJ38usCSDe5F9gR2tECt3zu': 'landmark_train.csv',\n",
    "    '15lwipssmC_K82ukRfb0uVCiDH1TZ3QCf': 'landmark_test.csv',\n",
    "    '1nIo1_wBmkovz-u_BCsV5c1Kbz6ZqoKwq': 'landmark_val.csv'\n",
    "}\n",
    "\n",
    "# Directory to save files\n",
    "output_dir = 'data2/'\n",
    "\n",
    "# Loop through the file IDs and download with new names\n",
    "for file_id, new_name in file_mapping.items():\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    output = f'{output_dir}{new_name}'  # Use the new name here\n",
    "    # If the file already exists, skip the download\n",
    "    if os.path.exists(output):\n",
    "        print(f'{output} already exists, skipping download')\n",
    "        continue\n",
    "    gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(63, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.4),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.4),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.6),\n",
    "        nn.Linear(128, len(list_label))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Hoàn thành đoạn code để thực hiện foward dự đoán cử chỉ với input x.\n",
    "        thực hiện flatten x\n",
    "        pass x vừa flatten vào linear_relu_stack\n",
    "        Return logits (outputs từ layer cuối cùng)'''\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "    def predict(self, x, threshould = 0.8):\n",
    "        logits = self(x)\n",
    "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
    "        chosen_ind = torch.argmax(softmax_prob, dim=1)\n",
    "        return torch.where(softmax_prob[0, chosen_ind] > threshould, chosen_ind, -1)\n",
    "\n",
    "    def predict_with_known_class(self, x):\n",
    "        logits = self(x)\n",
    "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
    "        return torch.argmax(softmax_prob, dim=1)\n",
    "\n",
    "    def score(self, logits):\n",
    "        return -torch.amax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_dict_from_config_file(relative_path):\n",
    "    with open(relative_path,\"r\") as f:\n",
    "       label_tag = yaml.full_load(f)[\"gestures\"]\n",
    "    return label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandLandmarksDetector():\n",
    "    def __init__(self) -> None:\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.detector = self.mp_hands.Hands(False,max_num_hands=1,min_detection_confidence=0.5)\n",
    "\n",
    "    def detectHand(self,frame):\n",
    "        hands = []\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        annotated_image = frame.copy()\n",
    "        results = self.detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                hand = []\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    annotated_image,\n",
    "                    hand_landmarks,\n",
    "                    self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    self.mp_drawing_styles.get_default_hand_connections_style())\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    x,y,z = landmark.x,landmark.y,landmark.z\n",
    "                    hand.extend([x,y,z])\n",
    "            hands.append(hand)\n",
    "        return hands,annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = pd.read_csv(data_file)\n",
    "        self.labels = torch.from_numpy(self.data.iloc[:,0].to_numpy())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        one_hot_label = self.labels[idx]\n",
    "        torch_data = torch.from_numpy(self.data.iloc[idx,1:].to_numpy(dtype=np.float32))\n",
    "        return torch_data, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.watched_metrics = np.inf\n",
    "\n",
    "    def early_stop(self, current_value):\n",
    "        if current_value < self.watched_metrics:\n",
    "            self.watched_metrics = current_value\n",
    "            self.counter = 0\n",
    "        elif current_value > (self.watched_metrics + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, val_loader, model, loss_function, early_stopper, optimizer):\n",
    "    # add auroc score\n",
    "    best_vloss = 1_000_000\n",
    "    timestamp = datetime.now().strftime('%d-%m %H:%M')\n",
    "    for epoch in range(300):\n",
    "        #training step\n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        acc_train = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
    "        for batch_number,data in enumerate(trainloader):\n",
    "            inputs,labels = data\n",
    "\n",
    "            ''' Hoàn thành code để thực hiện reset gradients và dự đoán class cử\n",
    "            chỉ của inputs\n",
    "            '''\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs)\n",
    "\n",
    "            ''' Hoàn thành code để thực hiện tính loss dưa vào kết quả dự đoán\n",
    "            và labels, sau đó thực hiện backward và update parameters thông qua\n",
    "            optimizer\n",
    "            '''\n",
    "            loss = loss_function(preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_train.update(model.predict_with_known_class(inputs), labels)\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "\n",
    "        model.train(False)\n",
    "        running_vloss = 0.0\n",
    "        acc_val = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            preds = model(vinputs)\n",
    "            vloss = loss_function(preds, vlabels)\n",
    "            running_vloss += vloss.item()\n",
    "            acc_val.update(model.predict_with_known_class(vinputs), vlabels)\n",
    "\n",
    "        print(f\"Epoch {epoch}: \")\n",
    "        print(f\"Accuracy train:{acc_train.compute().item()}, val:{acc_val.compute().item()}\")\n",
    "        avg_vloss = running_vloss / len(val_loader)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "        print('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch + 1)\n",
    "        print('Training vs. Validation accuracy',\n",
    "                        { 'Training' : acc_train.compute().item()\n",
    "                        , 'Validation' : acc_val.compute().item() },\n",
    "                        epoch + 1)\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            best_model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_best'\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        if early_stopper.early_stop(avg_vloss):\n",
    "            ''' Hoàn thành đoạn code bên dướ để  print ra epoch hiện tại và\n",
    "            minimum watched metric và thoát loop\n",
    "            '''\n",
    "            print(f\"Early stopping at epoch {epoch} with minimum : {early_stopper.watched_metrics}\")\n",
    "            break\n",
    "\n",
    "    model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_last'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print(acc_val.compute())\n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      "Accuracy train:0.19795222580432892, val:0.19291338324546814\n",
      "LOSS train 1.6172916293144226 valid 1.6126845280329387\n",
      "Training vs. Validation Loss {'Training': 1.6172916293144226, 'Validation': 1.6126845280329387} 1\n",
      "Training vs. Validation accuracy {'Training': 0.19795222580432892, 'Validation': 0.19291338324546814} 1\n",
      "Epoch 1: \n",
      "Accuracy train:0.22184300422668457, val:0.18897637724876404\n",
      "LOSS train 1.611766830086708 valid 1.6110198100407918\n",
      "Training vs. Validation Loss {'Training': 1.611766830086708, 'Validation': 1.6110198100407918} 2\n",
      "Training vs. Validation accuracy {'Training': 0.22184300422668457, 'Validation': 0.18897637724876404} 2\n",
      "Epoch 2: \n",
      "Accuracy train:0.2593856751918793, val:0.18503937125205994\n",
      "LOSS train 1.603277787566185 valid 1.6069459716478984\n",
      "Training vs. Validation Loss {'Training': 1.603277787566185, 'Validation': 1.6069459716478984} 3\n",
      "Training vs. Validation accuracy {'Training': 0.2593856751918793, 'Validation': 0.18503937125205994} 3\n",
      "Epoch 3: \n",
      "Accuracy train:0.2935153543949127, val:0.3385826647281647\n",
      "LOSS train 1.5995768010616302 valid 1.5989327828089397\n",
      "Training vs. Validation Loss {'Training': 1.5995768010616302, 'Validation': 1.5989327828089397} 4\n",
      "Training vs. Validation accuracy {'Training': 0.2935153543949127, 'Validation': 0.3385826647281647} 4\n",
      "Epoch 4: \n",
      "Accuracy train:0.2696245610713959, val:0.3818897604942322\n",
      "LOSS train 1.6006953418254852 valid 1.5905927220980327\n",
      "Training vs. Validation Loss {'Training': 1.6006953418254852, 'Validation': 1.5905927220980327} 5\n",
      "Training vs. Validation accuracy {'Training': 0.2696245610713959, 'Validation': 0.3818897604942322} 5\n",
      "Epoch 5: \n",
      "Accuracy train:0.31740614771842957, val:0.4527558982372284\n",
      "LOSS train 1.5856112092733383 valid 1.583700676759084\n",
      "Training vs. Validation Loss {'Training': 1.5856112092733383, 'Validation': 1.583700676759084} 6\n",
      "Training vs. Validation accuracy {'Training': 0.31740614771842957, 'Validation': 0.4527558982372284} 6\n",
      "Epoch 6: \n",
      "Accuracy train:0.3139931857585907, val:0.4763779640197754\n",
      "LOSS train 1.5750930309295654 valid 1.5760802030563354\n",
      "Training vs. Validation Loss {'Training': 1.5750930309295654, 'Validation': 1.5760802030563354} 7\n",
      "Training vs. Validation accuracy {'Training': 0.3139931857585907, 'Validation': 0.4763779640197754} 7\n",
      "Epoch 7: \n",
      "Accuracy train:0.39590445160865784, val:0.4645669162273407\n",
      "LOSS train 1.5710904151201248 valid 1.5717006921768188\n",
      "Training vs. Validation Loss {'Training': 1.5710904151201248, 'Validation': 1.5717006921768188} 8\n",
      "Training vs. Validation accuracy {'Training': 0.39590445160865784, 'Validation': 0.4645669162273407} 8\n",
      "Epoch 8: \n",
      "Accuracy train:0.372013658285141, val:0.4763779640197754\n",
      "LOSS train 1.5627149194478989 valid 1.5649170676867168\n",
      "Training vs. Validation Loss {'Training': 1.5627149194478989, 'Validation': 1.5649170676867168} 9\n",
      "Training vs. Validation accuracy {'Training': 0.372013658285141, 'Validation': 0.4763779640197754} 9\n",
      "Epoch 9: \n",
      "Accuracy train:0.34812286496162415, val:0.4645669162273407\n",
      "LOSS train 1.5535581558942795 valid 1.559416115283966\n",
      "Training vs. Validation Loss {'Training': 1.5535581558942795, 'Validation': 1.559416115283966} 10\n",
      "Training vs. Validation accuracy {'Training': 0.34812286496162415, 'Validation': 0.4645669162273407} 10\n",
      "Epoch 10: \n",
      "Accuracy train:0.40614333748817444, val:0.4803149700164795\n",
      "LOSS train 1.5569936335086823 valid 1.5515877803166707\n",
      "Training vs. Validation Loss {'Training': 1.5569936335086823, 'Validation': 1.5515877803166707} 11\n",
      "Training vs. Validation accuracy {'Training': 0.40614333748817444, 'Validation': 0.4803149700164795} 11\n",
      "Epoch 11: \n",
      "Accuracy train:0.40614333748817444, val:0.4803149700164795\n",
      "LOSS train 1.5433817207813263 valid 1.5432318051656086\n",
      "Training vs. Validation Loss {'Training': 1.5433817207813263, 'Validation': 1.5432318051656086} 12\n",
      "Training vs. Validation accuracy {'Training': 0.40614333748817444, 'Validation': 0.4803149700164795} 12\n",
      "Epoch 12: \n",
      "Accuracy train:0.46075084805488586, val:0.5511810779571533\n",
      "LOSS train 1.5318368673324585 valid 1.5333486795425415\n",
      "Training vs. Validation Loss {'Training': 1.5318368673324585, 'Validation': 1.5333486795425415} 13\n",
      "Training vs. Validation accuracy {'Training': 0.46075084805488586, 'Validation': 0.5511810779571533} 13\n",
      "Epoch 13: \n",
      "Accuracy train:0.46075084805488586, val:0.5354330539703369\n",
      "LOSS train 1.5182257145643234 valid 1.5223952730496724\n",
      "Training vs. Validation Loss {'Training': 1.5182257145643234, 'Validation': 1.5223952730496724} 14\n",
      "Training vs. Validation accuracy {'Training': 0.46075084805488586, 'Validation': 0.5354330539703369} 14\n",
      "Epoch 14: \n",
      "Accuracy train:0.48122867941856384, val:0.5708661675453186\n",
      "LOSS train 1.5016656816005707 valid 1.5105998317400615\n",
      "Training vs. Validation Loss {'Training': 1.5016656816005707, 'Validation': 1.5105998317400615} 15\n",
      "Training vs. Validation accuracy {'Training': 0.48122867941856384, 'Validation': 0.5708661675453186} 15\n",
      "Epoch 15: \n",
      "Accuracy train:0.44368600845336914, val:0.6141732335090637\n",
      "LOSS train 1.5017893463373184 valid 1.491188903649648\n",
      "Training vs. Validation Loss {'Training': 1.5017893463373184, 'Validation': 1.491188903649648} 16\n",
      "Training vs. Validation accuracy {'Training': 0.44368600845336914, 'Validation': 0.6141732335090637} 16\n",
      "Epoch 16: \n",
      "Accuracy train:0.5426621437072754, val:0.6062992215156555\n",
      "LOSS train 1.4702651649713516 valid 1.4719823002815247\n",
      "Training vs. Validation Loss {'Training': 1.4702651649713516, 'Validation': 1.4719823002815247} 17\n",
      "Training vs. Validation accuracy {'Training': 0.5426621437072754, 'Validation': 0.6062992215156555} 17\n",
      "Epoch 17: \n",
      "Accuracy train:0.5392491221427917, val:0.6417322754859924\n",
      "LOSS train 1.4547306299209595 valid 1.448568046092987\n",
      "Training vs. Validation Loss {'Training': 1.4547306299209595, 'Validation': 1.448568046092987} 18\n",
      "Training vs. Validation accuracy {'Training': 0.5392491221427917, 'Validation': 0.6417322754859924} 18\n",
      "Epoch 18: \n",
      "Accuracy train:0.5563139915466309, val:0.6299212574958801\n",
      "LOSS train 1.4220240414142609 valid 1.4236810008684795\n",
      "Training vs. Validation Loss {'Training': 1.4220240414142609, 'Validation': 1.4236810008684795} 19\n",
      "Training vs. Validation accuracy {'Training': 0.5563139915466309, 'Validation': 0.6299212574958801} 19\n",
      "Epoch 19: \n",
      "Accuracy train:0.5597269535064697, val:0.6496062874794006\n",
      "LOSS train 1.4112301617860794 valid 1.3922714789708455\n",
      "Training vs. Validation Loss {'Training': 1.4112301617860794, 'Validation': 1.3922714789708455} 20\n",
      "Training vs. Validation accuracy {'Training': 0.5597269535064697, 'Validation': 0.6496062874794006} 20\n",
      "Epoch 20: \n",
      "Accuracy train:0.5460751056671143, val:0.6692913174629211\n",
      "LOSS train 1.3560272008180618 valid 1.3540212114651997\n",
      "Training vs. Validation Loss {'Training': 1.3560272008180618, 'Validation': 1.3540212114651997} 21\n",
      "Training vs. Validation accuracy {'Training': 0.5460751056671143, 'Validation': 0.6692913174629211} 21\n",
      "Epoch 21: \n",
      "Accuracy train:0.5802047848701477, val:0.7007874250411987\n",
      "LOSS train 1.3423504680395126 valid 1.3156780401865642\n",
      "Training vs. Validation Loss {'Training': 1.3423504680395126, 'Validation': 1.3156780401865642} 22\n",
      "Training vs. Validation accuracy {'Training': 0.5802047848701477, 'Validation': 0.7007874250411987} 22\n",
      "Epoch 22: \n",
      "Accuracy train:0.61774742603302, val:0.7165354490280151\n",
      "LOSS train 1.2922408878803253 valid 1.2620283563931782\n",
      "Training vs. Validation Loss {'Training': 1.2922408878803253, 'Validation': 1.2620283563931782} 23\n",
      "Training vs. Validation accuracy {'Training': 0.61774742603302, 'Validation': 0.7165354490280151} 23\n",
      "Epoch 23: \n",
      "Accuracy train:0.6689419746398926, val:0.712598443031311\n",
      "LOSS train 1.2327460646629333 valid 1.2009083926677704\n",
      "Training vs. Validation Loss {'Training': 1.2327460646629333, 'Validation': 1.2009083926677704} 24\n",
      "Training vs. Validation accuracy {'Training': 0.6689419746398926, 'Validation': 0.712598443031311} 24\n",
      "Epoch 24: \n",
      "Accuracy train:0.6757678985595703, val:0.751968502998352\n",
      "LOSS train 1.187056988477707 valid 1.1414508720239003\n",
      "Training vs. Validation Loss {'Training': 1.187056988477707, 'Validation': 1.1414508720239003} 25\n",
      "Training vs. Validation accuracy {'Training': 0.6757678985595703, 'Validation': 0.751968502998352} 25\n",
      "Epoch 25: \n",
      "Accuracy train:0.6689419746398926, val:0.7322834730148315\n",
      "LOSS train 1.1641355007886887 valid 1.064555009206136\n",
      "Training vs. Validation Loss {'Training': 1.1641355007886887, 'Validation': 1.064555009206136} 26\n",
      "Training vs. Validation accuracy {'Training': 0.6689419746398926, 'Validation': 0.7322834730148315} 26\n",
      "Epoch 26: \n",
      "Accuracy train:0.6860068440437317, val:0.8031495809555054\n",
      "LOSS train 1.069124385714531 valid 1.0106478333473206\n",
      "Training vs. Validation Loss {'Training': 1.069124385714531, 'Validation': 1.0106478333473206} 27\n",
      "Training vs. Validation accuracy {'Training': 0.6860068440437317, 'Validation': 0.8031495809555054} 27\n",
      "Epoch 27: \n",
      "Accuracy train:0.7133105993270874, val:0.8110235929489136\n",
      "LOSS train 1.030617855489254 valid 0.9441407968600591\n",
      "Training vs. Validation Loss {'Training': 1.030617855489254, 'Validation': 0.9441407968600591} 28\n",
      "Training vs. Validation accuracy {'Training': 0.7133105993270874, 'Validation': 0.8110235929489136} 28\n",
      "Epoch 28: \n",
      "Accuracy train:0.7542662024497986, val:0.8385826945304871\n",
      "LOSS train 0.9647226110100746 valid 0.8724219451347986\n",
      "Training vs. Validation Loss {'Training': 0.9647226110100746, 'Validation': 0.8724219451347986} 29\n",
      "Training vs. Validation accuracy {'Training': 0.7542662024497986, 'Validation': 0.8385826945304871} 29\n",
      "Epoch 29: \n",
      "Accuracy train:0.7747440338134766, val:0.8503937125205994\n",
      "LOSS train 0.9128937423229218 valid 0.8059752285480499\n",
      "Training vs. Validation Loss {'Training': 0.9128937423229218, 'Validation': 0.8059752285480499} 30\n",
      "Training vs. Validation accuracy {'Training': 0.7747440338134766, 'Validation': 0.8503937125205994} 30\n",
      "Epoch 30: \n",
      "Accuracy train:0.7918089032173157, val:0.8937007784843445\n",
      "LOSS train 0.8344393521547318 valid 0.7331707179546356\n",
      "Training vs. Validation Loss {'Training': 0.8344393521547318, 'Validation': 0.7331707179546356} 31\n",
      "Training vs. Validation accuracy {'Training': 0.7918089032173157, 'Validation': 0.8937007784843445} 31\n",
      "Epoch 31: \n",
      "Accuracy train:0.8122866749763489, val:0.8700787425041199\n",
      "LOSS train 0.7916035875678062 valid 0.6754288325707117\n",
      "Training vs. Validation Loss {'Training': 0.7916035875678062, 'Validation': 0.6754288325707117} 32\n",
      "Training vs. Validation accuracy {'Training': 0.8122866749763489, 'Validation': 0.8700787425041199} 32\n",
      "Epoch 32: \n",
      "Accuracy train:0.8395904302597046, val:0.9173228144645691\n",
      "LOSS train 0.7547341138124466 valid 0.6102339848876\n",
      "Training vs. Validation Loss {'Training': 0.7547341138124466, 'Validation': 0.6102339848876} 33\n",
      "Training vs. Validation accuracy {'Training': 0.8395904302597046, 'Validation': 0.9173228144645691} 33\n",
      "Epoch 33: \n",
      "Accuracy train:0.8600682616233826, val:0.9330708384513855\n",
      "LOSS train 0.6496133357286453 valid 0.5493510042627653\n",
      "Training vs. Validation Loss {'Training': 0.6496133357286453, 'Validation': 0.5493510042627653} 34\n",
      "Training vs. Validation accuracy {'Training': 0.8600682616233826, 'Validation': 0.9330708384513855} 34\n",
      "Epoch 34: \n",
      "Accuracy train:0.8600682616233826, val:0.9448819160461426\n",
      "LOSS train 0.6579622179269791 valid 0.49132602165142697\n",
      "Training vs. Validation Loss {'Training': 0.6579622179269791, 'Validation': 0.49132602165142697} 35\n",
      "Training vs. Validation accuracy {'Training': 0.8600682616233826, 'Validation': 0.9448819160461426} 35\n",
      "Epoch 35: \n",
      "Accuracy train:0.894197940826416, val:0.9763779640197754\n",
      "LOSS train 0.5842967294156551 valid 0.4345291331410408\n",
      "Training vs. Validation Loss {'Training': 0.5842967294156551, 'Validation': 0.4345291331410408} 36\n",
      "Training vs. Validation accuracy {'Training': 0.894197940826416, 'Validation': 0.9763779640197754} 36\n",
      "Epoch 36: \n",
      "Accuracy train:0.9078498482704163, val:0.9763779640197754\n",
      "LOSS train 0.5279305130243301 valid 0.3868061775962512\n",
      "Training vs. Validation Loss {'Training': 0.5279305130243301, 'Validation': 0.3868061775962512} 37\n",
      "Training vs. Validation accuracy {'Training': 0.9078498482704163, 'Validation': 0.9763779640197754} 37\n",
      "Epoch 37: \n",
      "Accuracy train:0.914675772190094, val:0.9763779640197754\n",
      "LOSS train 0.4953557774424553 valid 0.3513130098581314\n",
      "Training vs. Validation Loss {'Training': 0.4953557774424553, 'Validation': 0.3513130098581314} 38\n",
      "Training vs. Validation accuracy {'Training': 0.914675772190094, 'Validation': 0.9763779640197754} 38\n",
      "Epoch 38: \n",
      "Accuracy train:0.9658703207969666, val:0.9763779640197754\n",
      "LOSS train 0.44189854338765144 valid 0.3035468316326539\n",
      "Training vs. Validation Loss {'Training': 0.44189854338765144, 'Validation': 0.3035468316326539} 39\n",
      "Training vs. Validation accuracy {'Training': 0.9658703207969666, 'Validation': 0.9763779640197754} 39\n",
      "Epoch 39: \n",
      "Accuracy train:0.9385665655136108, val:0.9724409580230713\n",
      "LOSS train 0.37258828058838844 valid 0.2686650886510809\n",
      "Training vs. Validation Loss {'Training': 0.37258828058838844, 'Validation': 0.2686650886510809} 40\n",
      "Training vs. Validation accuracy {'Training': 0.9385665655136108, 'Validation': 0.9724409580230713} 40\n",
      "Epoch 40: \n",
      "Accuracy train:0.9726962447166443, val:0.9724409580230713\n",
      "LOSS train 0.34764556027948856 valid 0.22128436900675297\n",
      "Training vs. Validation Loss {'Training': 0.34764556027948856, 'Validation': 0.22128436900675297} 41\n",
      "Training vs. Validation accuracy {'Training': 0.9726962447166443, 'Validation': 0.9724409580230713} 41\n",
      "Epoch 41: \n",
      "Accuracy train:0.9692832827568054, val:0.9763779640197754\n",
      "LOSS train 0.31644702330231667 valid 0.18765953369438648\n",
      "Training vs. Validation Loss {'Training': 0.31644702330231667, 'Validation': 0.18765953369438648} 42\n",
      "Training vs. Validation accuracy {'Training': 0.9692832827568054, 'Validation': 0.9763779640197754} 42\n",
      "Epoch 42: \n",
      "Accuracy train:0.9829351305961609, val:0.9763779640197754\n",
      "LOSS train 0.2911366429179907 valid 0.1743018478155136\n",
      "Training vs. Validation Loss {'Training': 0.2911366429179907, 'Validation': 0.1743018478155136} 43\n",
      "Training vs. Validation accuracy {'Training': 0.9829351305961609, 'Validation': 0.9763779640197754} 43\n",
      "Epoch 43: \n",
      "Accuracy train:0.9761092066764832, val:0.9724409580230713\n",
      "LOSS train 0.2527316324412823 valid 0.15745339775457978\n",
      "Training vs. Validation Loss {'Training': 0.2527316324412823, 'Validation': 0.15745339775457978} 44\n",
      "Training vs. Validation accuracy {'Training': 0.9761092066764832, 'Validation': 0.9724409580230713} 44\n",
      "Epoch 44: \n",
      "Accuracy train:0.9897611141204834, val:0.9724409580230713\n",
      "LOSS train 0.21784033067524433 valid 0.1331693778435389\n",
      "Training vs. Validation Loss {'Training': 0.21784033067524433, 'Validation': 0.1331693778435389} 45\n",
      "Training vs. Validation accuracy {'Training': 0.9897611141204834, 'Validation': 0.9724409580230713} 45\n",
      "Epoch 45: \n",
      "Accuracy train:0.979522168636322, val:0.9724409580230713\n",
      "LOSS train 0.2175502646714449 valid 0.12227065643916528\n",
      "Training vs. Validation Loss {'Training': 0.2175502646714449, 'Validation': 0.12227065643916528} 46\n",
      "Training vs. Validation accuracy {'Training': 0.979522168636322, 'Validation': 0.9724409580230713} 46\n",
      "Epoch 46: \n",
      "Accuracy train:0.9965870380401611, val:0.9724409580230713\n",
      "LOSS train 0.18469436466693878 valid 0.11192060153310497\n",
      "Training vs. Validation Loss {'Training': 0.18469436466693878, 'Validation': 0.11192060153310497} 47\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9724409580230713} 47\n",
      "Epoch 47: \n",
      "Accuracy train:0.9897611141204834, val:0.9724409580230713\n",
      "LOSS train 0.20187292620539665 valid 0.104127564933151\n",
      "Training vs. Validation Loss {'Training': 0.20187292620539665, 'Validation': 0.104127564933151} 48\n",
      "Training vs. Validation accuracy {'Training': 0.9897611141204834, 'Validation': 0.9724409580230713} 48\n",
      "Epoch 48: \n",
      "Accuracy train:0.9965870380401611, val:0.9724409580230713\n",
      "LOSS train 0.16140259616076946 valid 0.0958311955910176\n",
      "Training vs. Validation Loss {'Training': 0.16140259616076946, 'Validation': 0.0958311955910176} 49\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9724409580230713} 49\n",
      "Epoch 49: \n",
      "Accuracy train:0.9931740760803223, val:0.9724409580230713\n",
      "LOSS train 0.1533595435321331 valid 0.08629103718946378\n",
      "Training vs. Validation Loss {'Training': 0.1533595435321331, 'Validation': 0.08629103718946378} 50\n",
      "Training vs. Validation accuracy {'Training': 0.9931740760803223, 'Validation': 0.9724409580230713} 50\n",
      "Epoch 50: \n",
      "Accuracy train:0.9931740760803223, val:0.9763779640197754\n",
      "LOSS train 0.14276884961873293 valid 0.08042824811612566\n",
      "Training vs. Validation Loss {'Training': 0.14276884961873293, 'Validation': 0.08042824811612566} 51\n",
      "Training vs. Validation accuracy {'Training': 0.9931740760803223, 'Validation': 0.9763779640197754} 51\n",
      "Epoch 51: \n",
      "Accuracy train:0.9863481521606445, val:0.9763779640197754\n",
      "LOSS train 0.09539753943681717 valid 0.07389454714333017\n",
      "Training vs. Validation Loss {'Training': 0.09539753943681717, 'Validation': 0.07389454714333017} 52\n",
      "Training vs. Validation accuracy {'Training': 0.9863481521606445, 'Validation': 0.9763779640197754} 52\n",
      "Epoch 52: \n",
      "Accuracy train:0.9897611141204834, val:0.9763779640197754\n",
      "LOSS train 0.11462846072390676 valid 0.07513316643113892\n",
      "Training vs. Validation Loss {'Training': 0.11462846072390676, 'Validation': 0.07513316643113892} 53\n",
      "Training vs. Validation accuracy {'Training': 0.9897611141204834, 'Validation': 0.9763779640197754} 53\n",
      "Epoch 53: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.10566711146384478 valid 0.07638195056157808\n",
      "Training vs. Validation Loss {'Training': 0.10566711146384478, 'Validation': 0.07638195056157808} 54\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 54\n",
      "Epoch 54: \n",
      "Accuracy train:0.9931740760803223, val:0.9763779640197754\n",
      "LOSS train 0.0903389654122293 valid 0.06871054220634203\n",
      "Training vs. Validation Loss {'Training': 0.0903389654122293, 'Validation': 0.06871054220634203} 55\n",
      "Training vs. Validation accuracy {'Training': 0.9931740760803223, 'Validation': 0.9763779640197754} 55\n",
      "Epoch 55: \n",
      "Accuracy train:0.9931740760803223, val:0.9763779640197754\n",
      "LOSS train 0.09419802390038967 valid 0.06508013668159644\n",
      "Training vs. Validation Loss {'Training': 0.09419802390038967, 'Validation': 0.06508013668159644} 56\n",
      "Training vs. Validation accuracy {'Training': 0.9931740760803223, 'Validation': 0.9763779640197754} 56\n",
      "Epoch 56: \n",
      "Accuracy train:0.9863481521606445, val:0.9763779640197754\n",
      "LOSS train 0.11156435310840607 valid 0.06825745691700529\n",
      "Training vs. Validation Loss {'Training': 0.11156435310840607, 'Validation': 0.06825745691700529} 57\n",
      "Training vs. Validation accuracy {'Training': 0.9863481521606445, 'Validation': 0.9763779640197754} 57\n",
      "Epoch 57: \n",
      "Accuracy train:0.9863481521606445, val:0.9763779640197754\n",
      "LOSS train 0.08477252861484885 valid 0.06855840903396408\n",
      "Training vs. Validation Loss {'Training': 0.08477252861484885, 'Validation': 0.06855840903396408} 58\n",
      "Training vs. Validation accuracy {'Training': 0.9863481521606445, 'Validation': 0.9763779640197754} 58\n",
      "Epoch 58: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.06270875525660813 valid 0.06293576462970425\n",
      "Training vs. Validation Loss {'Training': 0.06270875525660813, 'Validation': 0.06293576462970425} 59\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 59\n",
      "Epoch 59: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.08236649632453918 valid 0.06153059867210686\n",
      "Training vs. Validation Loss {'Training': 0.08236649632453918, 'Validation': 0.06153059867210686} 60\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 60\n",
      "Epoch 60: \n",
      "Accuracy train:0.9965870380401611, val:0.9803149700164795\n",
      "LOSS train 0.07028479408472776 valid 0.05352065137897929\n",
      "Training vs. Validation Loss {'Training': 0.07028479408472776, 'Validation': 0.05352065137897929} 61\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9803149700164795} 61\n",
      "Epoch 61: \n",
      "Accuracy train:1.0, val:0.9803149700164795\n",
      "LOSS train 0.07169924397021532 valid 0.05316583851041893\n",
      "Training vs. Validation Loss {'Training': 0.07169924397021532, 'Validation': 0.05316583851041893} 62\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9803149700164795} 62\n",
      "Epoch 62: \n",
      "Accuracy train:0.9965870380401611, val:0.9724409580230713\n",
      "LOSS train 0.06401191046461463 valid 0.073564808020213\n",
      "Training vs. Validation Loss {'Training': 0.06401191046461463, 'Validation': 0.073564808020213} 63\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9724409580230713} 63\n",
      "Epoch 63: \n",
      "Accuracy train:0.9931740760803223, val:0.9763779640197754\n",
      "LOSS train 0.06918861018493772 valid 0.08324223927532633\n",
      "Training vs. Validation Loss {'Training': 0.06918861018493772, 'Validation': 0.08324223927532633} 64\n",
      "Training vs. Validation accuracy {'Training': 0.9931740760803223, 'Validation': 0.9763779640197754} 64\n",
      "Epoch 64: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.04947950365021825 valid 0.07022792141651735\n",
      "Training vs. Validation Loss {'Training': 0.04947950365021825, 'Validation': 0.07022792141651735} 65\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 65\n",
      "Epoch 65: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.055316790007054806 valid 0.06601937734133874\n",
      "Training vs. Validation Loss {'Training': 0.055316790007054806, 'Validation': 0.06601937734133874} 66\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 66\n",
      "Epoch 66: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.05080307275056839 valid 0.06512498708131413\n",
      "Training vs. Validation Loss {'Training': 0.05080307275056839, 'Validation': 0.06512498708131413} 67\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 67\n",
      "Epoch 67: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.031082161469385028 valid 0.06497764666952814\n",
      "Training vs. Validation Loss {'Training': 0.031082161469385028, 'Validation': 0.06497764666952814} 68\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 68\n",
      "Epoch 68: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.041064466116949916 valid 0.06701450723145778\n",
      "Training vs. Validation Loss {'Training': 0.041064466116949916, 'Validation': 0.06701450723145778} 69\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 69\n",
      "Epoch 69: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.03717104205861688 valid 0.06816222324656944\n",
      "Training vs. Validation Loss {'Training': 0.03717104205861688, 'Validation': 0.06816222324656944} 70\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 70\n",
      "Epoch 70: \n",
      "Accuracy train:0.9897611141204834, val:0.9763779640197754\n",
      "LOSS train 0.02820084837730974 valid 0.06538283035236721\n",
      "Training vs. Validation Loss {'Training': 0.02820084837730974, 'Validation': 0.06538283035236721} 71\n",
      "Training vs. Validation accuracy {'Training': 0.9897611141204834, 'Validation': 0.9763779640197754} 71\n",
      "Epoch 71: \n",
      "Accuracy train:0.9897611141204834, val:0.9763779640197754\n",
      "LOSS train 0.043890359927900136 valid 0.07146738170801352\n",
      "Training vs. Validation Loss {'Training': 0.043890359927900136, 'Validation': 0.07146738170801352} 72\n",
      "Training vs. Validation accuracy {'Training': 0.9897611141204834, 'Validation': 0.9763779640197754} 72\n",
      "Epoch 72: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.04657860181760043 valid 0.07495518865956304\n",
      "Training vs. Validation Loss {'Training': 0.04657860181760043, 'Validation': 0.07495518865956304} 73\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 73\n",
      "Epoch 73: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.04913875088095665 valid 0.06605035728231694\n",
      "Training vs. Validation Loss {'Training': 0.04913875088095665, 'Validation': 0.06605035728231694} 74\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 74\n",
      "Epoch 74: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.033544257283210754 valid 0.06193562395249804\n",
      "Training vs. Validation Loss {'Training': 0.033544257283210754, 'Validation': 0.06193562395249804} 75\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 75\n",
      "Epoch 75: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.03226772171910852 valid 0.061535386834293604\n",
      "Training vs. Validation Loss {'Training': 0.03226772171910852, 'Validation': 0.061535386834293604} 76\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 76\n",
      "Epoch 76: \n",
      "Accuracy train:0.9897611141204834, val:0.9763779640197754\n",
      "LOSS train 0.03856705280486494 valid 0.06492929931846447\n",
      "Training vs. Validation Loss {'Training': 0.03856705280486494, 'Validation': 0.06492929931846447} 77\n",
      "Training vs. Validation accuracy {'Training': 0.9897611141204834, 'Validation': 0.9763779640197754} 77\n",
      "Epoch 77: \n",
      "Accuracy train:0.9897611141204834, val:0.9763779640197754\n",
      "LOSS train 0.02992216986604035 valid 0.06790218951452213\n",
      "Training vs. Validation Loss {'Training': 0.02992216986604035, 'Validation': 0.06790218951452213} 78\n",
      "Training vs. Validation accuracy {'Training': 0.9897611141204834, 'Validation': 0.9763779640197754} 78\n",
      "Epoch 78: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.027914200793020427 valid 0.07125760366034228\n",
      "Training vs. Validation Loss {'Training': 0.027914200793020427, 'Validation': 0.07125760366034228} 79\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 79\n",
      "Epoch 79: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.03075592638924718 valid 0.06696055687401288\n",
      "Training vs. Validation Loss {'Training': 0.03075592638924718, 'Validation': 0.06696055687401288} 80\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 80\n",
      "Epoch 80: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.018475544988177717 valid 0.07051240941412591\n",
      "Training vs. Validation Loss {'Training': 0.018475544988177717, 'Validation': 0.07051240941412591} 81\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 81\n",
      "Epoch 81: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.02602506848052144 valid 0.0694536426308332\n",
      "Training vs. Validation Loss {'Training': 0.02602506848052144, 'Validation': 0.0694536426308332} 82\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 82\n",
      "Epoch 82: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.039635187247768044 valid 0.06748186435045984\n",
      "Training vs. Validation Loss {'Training': 0.039635187247768044, 'Validation': 0.06748186435045984} 83\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 83\n",
      "Epoch 83: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.02997710171621293 valid 0.07236046402249485\n",
      "Training vs. Validation Loss {'Training': 0.02997710171621293, 'Validation': 0.07236046402249485} 84\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 84\n",
      "Epoch 84: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.022961478680372238 valid 0.0676279821927892\n",
      "Training vs. Validation Loss {'Training': 0.022961478680372238, 'Validation': 0.0676279821927892} 85\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 85\n",
      "Epoch 85: \n",
      "Accuracy train:0.9965870380401611, val:0.9803149700164795\n",
      "LOSS train 0.022810484864749014 valid 0.06400637843519992\n",
      "Training vs. Validation Loss {'Training': 0.022810484864749014, 'Validation': 0.06400637843519992} 86\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9803149700164795} 86\n",
      "Epoch 86: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.02482666401192546 valid 0.07174048438416018\n",
      "Training vs. Validation Loss {'Training': 0.02482666401192546, 'Validation': 0.07174048438416018} 87\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 87\n",
      "Epoch 87: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.01645070075755939 valid 0.06749378936365247\n",
      "Training vs. Validation Loss {'Training': 0.01645070075755939, 'Validation': 0.06749378936365247} 88\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 88\n",
      "Epoch 88: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.014797339856158942 valid 0.06797735739625448\n",
      "Training vs. Validation Loss {'Training': 0.014797339856158942, 'Validation': 0.06797735739625448} 89\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 89\n",
      "Epoch 89: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.023985086474567652 valid 0.07988068809451458\n",
      "Training vs. Validation Loss {'Training': 0.023985086474567652, 'Validation': 0.07988068809451458} 90\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 90\n",
      "Epoch 90: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.01831817510537803 valid 0.07830240600257336\n",
      "Training vs. Validation Loss {'Training': 0.01831817510537803, 'Validation': 0.07830240600257336} 91\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 91\n",
      "Epoch 91: \n",
      "Accuracy train:0.9965870380401611, val:0.9763779640197754\n",
      "LOSS train 0.021327659429516643 valid 0.07340200658897326\n",
      "Training vs. Validation Loss {'Training': 0.021327659429516643, 'Validation': 0.07340200658897326} 92\n",
      "Training vs. Validation accuracy {'Training': 0.9965870380401611, 'Validation': 0.9763779640197754} 92\n",
      "Epoch 92: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.01894067449029535 valid 0.07425147551839473\n",
      "Training vs. Validation Loss {'Training': 0.01894067449029535, 'Validation': 0.07425147551839473} 93\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 93\n",
      "Epoch 93: \n",
      "Accuracy train:1.0, val:0.9763779640197754\n",
      "LOSS train 0.016149595729075372 valid 0.077603237516693\n",
      "Training vs. Validation Loss {'Training': 0.016149595729075372, 'Validation': 0.077603237516693} 94\n",
      "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 0.9763779640197754} 94\n",
      "Early stopping at epoch 93 with minimum : 0.05316583851041893\n",
      "tensor(0.9764)\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER_PATH=\"./data2/\"\n",
    "LIST_LABEL = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
    "train_path = os.path.join(DATA_FOLDER_PATH,\"landmark_train.csv\")\n",
    "val_path = os.path.join(DATA_FOLDER_PATH,\"landmark_val.csv\")\n",
    "save_path = './models'\n",
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "trainset = CustomImageDataset(train_path)\n",
    "'''Hoàn thành code để thực hiện khởi tạo DataLoader cho trainset với\n",
    "batch_size 40 và cho phép xáo trộn\n",
    "'''\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=40, shuffle=True)\n",
    "\n",
    "valset = CustomImageDataset(os.path.join(val_path))\n",
    "val_loader = torch.utils.data.DataLoader(valset,batch_size=50, shuffle=False)\n",
    "\n",
    "'''Hoàn thành code để thực hiện khởi tạo NeuralNetwork model đã xây dựng ở trên,\n",
    "khởi tạo hàm loss sử dụng CrossEntropyLoss và khởi tạo early stopper với patience\n",
    "là 30 và min_delta là 0.01\n",
    "'''\n",
    "model = NeuralNetwork()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "early_stopper = EarlyStopper(patience=30, min_delta=0.01)\n",
    "\n",
    "'''Hoàn thành code để thực hiện cấu hình Adam optimizer cho các tham số của\n",
    "model với tốc độ học là 0.0001\n",
    "'''\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "model, best_model_path = train(trainloader, val_loader, model, loss_function, early_stopper, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/landmark_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m list_label \u001b[38;5;241m=\u001b[39m label_dict_from_config_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhand_gesture.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m DATA_FOLDER_PATH\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m testset \u001b[38;5;241m=\u001b[39m \u001b[43mCustomImageDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_FOLDER_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlandmark_test.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m''' Hoàn thành code bên dưới để  khởi tạo DataLoader cho testset with batch size\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m20, không cho phép shuffle\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      8\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(testset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[109], line 3\u001b[0m, in \u001b[0;36mCustomImageDataset.__init__\u001b[1;34m(self, data_file)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_file):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy())\n",
      "File \u001b[1;32md:\\Enviroment\\computer_vision\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Enviroment\\computer_vision\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\Enviroment\\computer_vision\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Enviroment\\computer_vision\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\Enviroment\\computer_vision\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/landmark_test.csv'"
     ]
    }
   ],
   "source": [
    "list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
    "DATA_FOLDER_PATH=\"./data2/\"\n",
    "testset = CustomImageDataset(os.path.join(DATA_FOLDER_PATH,\"landmark_test.csv\"))\n",
    "\n",
    "''' Hoàn thành code bên dưới để  khởi tạo DataLoader cho testset with batch size\n",
    "20, không cho phép shuffle\n",
    "'''\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=20, shuffle=False)\n",
    "\n",
    "network = NeuralNetwork()\n",
    "network.load_state_dict(torch.load(best_model_path, weights_only=False))\n",
    "\n",
    "network.eval()\n",
    "acc_test = Accuracy(num_classes=len(list_label), task='MULTICLASS')\n",
    "for i, test_data in enumerate(test_loader):\n",
    "    test_input, test_label = test_data\n",
    "\n",
    "    '''Hoàn thành code bên dưới để  predict class của cử chỉ và update accuracy\n",
    "    với kết quả predict và true labels\n",
    "    '''\n",
    "    preds = network(test_input)\n",
    "    acc_test.update(preds, test_label)\n",
    "\n",
    "print(network.__class__.__name__)\n",
    "print(f\"Accuracy of model:{acc_test.compute().item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
