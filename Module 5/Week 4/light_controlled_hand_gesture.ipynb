{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tôi import các thư viện như sau:\n",
    "# os : Tương tác với hệ điều hành\n",
    "# cv2 : Thư viện của OpenCV để xử lý ảnh và video\n",
    "# csv : Để đọc và ghi các file csv\n",
    "# yaml : Để đọc và ghi các file yaml\n",
    "# numpy : Xử lý mảng và tính toán ma trận\n",
    "# mediapipe : Framework của google để nhận diện bàn tay và các land mark\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import yaml\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "+ Chức năng : Kiểm tra ký tự nhập vào có phải là chữ cái thường không\n",
    "hay là khoảng trắng không.\n",
    "\n",
    "Ghi chú : Assign class như trong file yaml config từ 0 trở đi tương ứng\n",
    "với phím trên bàn phím. Như 'a' tương ứng với 0, 'b' tương ứng với 1, ...\n",
    "'''\n",
    "\n",
    "def is_handsign_character(char:str):\n",
    "    return ord('a') <= ord(char) <= ord('q') or char == \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Đọc file yaml (hand_gesture) và trả về một dictionary chứa các nhãn (cử chỉ)\n",
    "với mục đích là sử dụng các label này để gắn nhãn cho dữ liệu thu thập.\n",
    "'''\n",
    "\n",
    "def label_dict_from_config(relative_path):\n",
    "    with open(relative_path, \"r\") as f:\n",
    "        label_tag = yaml.full_load(f)[\"gestures\"]\n",
    "    return label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ghi dữ liệu (landmark) và label vào file csv\n",
    "__init__ : Mở file csv để ghi dữ liệu\n",
    "add : Thêm dữ liệu vào file csv bao gồm nhãn và tọa độ\n",
    "close : Đóng file csv sau khi hoàn tất\n",
    "'''\n",
    "\n",
    "class HandDatasetWriter():\n",
    "    def __init__(self, filepath) -> None:\n",
    "        self.csv_file = open(filepath, \"a\")\n",
    "        self.file_writer = csv.writer(self.csv_file, delimiter=\",\", quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    def add(self, hand, label):\n",
    "        self.file_writer.writerow([label, *np.array(hand).flatten().tolist()])\n",
    "    def close(self):\n",
    "        self.csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Phát hiện bàn tay trong khung và trích xuất các landmark\n",
    "__init__ : Khởi tạo thành phần cần thiết của Mediapipe để nhận diện bàn tay\n",
    "detetctHand :\n",
    "- Chuyển đổi frame từ BGR sang RGB.\n",
    "- Sử dụng mediapipe để nhận diện bàn tay và trích xuất các landmark.\n",
    "- Trả về danh sách các landmark và hình ảnh đã vẽ.\n",
    "'''\n",
    "\n",
    "class HandLandmarkDetector():\n",
    "    def __init__(self) -> None:\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.detector = self.mp_hands.Hands(False, max_num_hands=1, \n",
    "                                            min_detection_confidence=0.5)\n",
    "        \n",
    "    def detectHand(self, frame):\n",
    "        hands = []\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        annotated_image = frame.copy()\n",
    "        result = self.detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        if result.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                hand = []\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    annotated_image, \n",
    "                    hand_landmarks, \n",
    "                    self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    self.mp_drawing_styles.get_default_hand_connections_style()\n",
    "                )\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    x,y,z = landmark.x, landmark.y, landmark.z\n",
    "                    hand.extend([x,y,z])\n",
    "            hands.append(hand)\n",
    "        return hands, annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vòng lặp chính để thu thập dữ liệu cử chỉ\n",
    "def run(data_path, sign_img_path, split = \"val\", resolution = (1280, 720)):\n",
    "    '''\n",
    "    Parameters :\n",
    "    - data_path : Đường dẫn lưu dữ liệu CSV\n",
    "    - sign_img_path : Đường dẫn lưu hình ảnh cử chỉ\n",
    "    - split : Phân loại dữ liệu (train, val, test)\n",
    "    - resolution : Độ phân giải của webcam\n",
    "    Flow : \n",
    "    - Khởi tạo HandLandmarkDetector() để nhận diện và mở cam\n",
    "    - Tạo các thư mục cần thiết\n",
    "    - Vòng lặp chính :\n",
    "        + Đọc frame từ cam\n",
    "        + Nhận diện bàn tay và trích xuất landmark\n",
    "        + Xử lý trạng thái ghi dữ liệu dựa trên phím bấm\n",
    "        + Ghi dữ liệu khi cần thiết\n",
    "        + Hiển thị thông tin lên màn hình\n",
    "    '''\n",
    "    hand_detector = HandLandmarkDetector()\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cam.set(3, resolution[0])\n",
    "    cam.set(4, resolution[1])\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    os.makedirs(sign_img_path, exist_ok=True)\n",
    "    print(sign_img_path)\n",
    "    dataset_path = f\"./{data_path}/landmark_{split}.csv\"\n",
    "    hand_dataset = HandDatasetWriter(dataset_path)\n",
    "    current_letter = None\n",
    "    status_text = None\n",
    "    cannot_swith_char = False\n",
    "\n",
    "    saved_frame = None\n",
    "    while cam.isOpened():\n",
    "        _, frame = cam.read()\n",
    "        hands, annotated_image = hand_detector.detectHand(frame)\n",
    "\n",
    "        if (current_letter is None):\n",
    "            status_text = \"Press a to start recording\"\n",
    "        else:\n",
    "            label = ord(current_letter) - ord('a')\n",
    "            if label == -65:\n",
    "                status_text = f\"Recording unknown, press space to stop\"\n",
    "                label = -1\n",
    "            else:\n",
    "                status_text = f\"Recording {LABEL_TAG[label]}, press {current_letter} again to stop\"\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if (key == -1):\n",
    "            if (current_letter is None):\n",
    "                pass\n",
    "            else:\n",
    "                if len(hands) != 0:\n",
    "                    hand = hands[0]\n",
    "                    hand_dataset.add(hand=hand, label=label)\n",
    "                    saved_frame = frame\n",
    "\n",
    "        else:\n",
    "            key = chr(key)\n",
    "            if key == 'q':\n",
    "                break\n",
    "            if (is_handsign_character(key)):\n",
    "                if (current_letter is None):\n",
    "                    current_letter = key\n",
    "                elif (current_letter == key):\n",
    "                    if saved_frame is not None:\n",
    "                        if label >= 0:\n",
    "                            cv2.imwrite(f\"./{sign_img_path}/{LABEL_TAG[label]}.jpg\", saved_frame)\n",
    "                        cannot_swith_char = False\n",
    "                        current_letter = None\n",
    "                        saved_frame = None\n",
    "                else:\n",
    "                    cannot_swith_char = True\n",
    "        if cannot_swith_char:\n",
    "            cv2.putText(annotated_image, f\"please press {current_letter} again to stop unbind\",\n",
    "                        (0, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(annotated_image, status_text, (5, 20), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(f\"{split}\", annotated_image)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Điểm bắt đầu của chương trình\n",
    "if __name__ == \"__main__\":\n",
    "    '''\n",
    "    Flow :\n",
    "    - Đọc class từ file yaml\n",
    "    - Thiếp lập đường dẫn lưu dữ liệu và hình ảnh\n",
    "    - Gọi run 3 lần để xây dựng dữ liệu train, val, test\n",
    "    '''\n",
    "    LABEL_TAG = label_dict_from_config(\"hand_gesture.yaml\")\n",
    "    data_path = \"./data2\"\n",
    "    sign_img_path = \"./sign_img2\"\n",
    "    run(data_path, sign_img_path, \"train\", (1280, 720))\n",
    "    run(data_path, sign_img_path, \"val\", (1280, 720))\n",
    "    run(data_path, sign_img_path, \"test\", (1280, 720))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
